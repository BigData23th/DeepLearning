{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddded2a5f13949b1a362857fa36e3303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11e4eb93183c4dadbd84ac0824f52ac8",
              "IPY_MODEL_2e4521fb01fd45759aea0cf063e1891f",
              "IPY_MODEL_348615891e294b298adbe4f9916da5d6"
            ],
            "layout": "IPY_MODEL_e145313f3c714d24baa877d47dfefad6"
          }
        },
        "11e4eb93183c4dadbd84ac0824f52ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b348d98ad194f39aaaa2d96a2f549e3",
            "placeholder": "​",
            "style": "IPY_MODEL_fa58533093b54d47afcc2e9da782d49d",
            "value": "  0%"
          }
        },
        "2e4521fb01fd45759aea0cf063e1891f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f27fb097846449d82a45989aa85166a",
            "max": 3592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1335e49cd4274a068edf645162a83818",
            "value": 0
          }
        },
        "348615891e294b298adbe4f9916da5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d99c601e7e40421ab37b95dda27ba7e5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c0acb7a783d4fb991bfb9049fbd13e1",
            "value": " 0/3592 [00:00&lt;?, ?it/s]"
          }
        },
        "e145313f3c714d24baa877d47dfefad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b348d98ad194f39aaaa2d96a2f549e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa58533093b54d47afcc2e9da782d49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f27fb097846449d82a45989aa85166a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1335e49cd4274a068edf645162a83818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d99c601e7e40421ab37b95dda27ba7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0acb7a783d4fb991bfb9049fbd13e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyeongvv/DeepLearning_jy/blob/main/jyeongvv/DL_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "Ww4ZmwhFAO7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8mUWwkM-7eSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec2a79a-3a48-46c1-b557-ee21cff3501d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 02:02:48--  https://github.com/BigData23th/Data/raw/main/corpus.txt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/corpus.txt [following]\n",
            "--2023-04-07 02:02:48--  https://raw.githubusercontent.com/BigData23th/Data/main/corpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253511 (248K) [text/plain]\n",
            "Saving to: ‘corpus.txt’\n",
            "\n",
            "corpus.txt          100%[===================>] 247.57K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-04-07 02:02:49 (45.2 MB/s) - ‘corpus.txt’ saved [253511/253511]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tab-delimited Bilingual Sentence Pairs\n",
        "# 출처 : http://www.manythings.org/anki\n",
        "!wget https://github.com/BigData23th/Data/raw/main/corpus.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 파일을 전처리\n",
        "\n",
        "import string # punctuation\n",
        "\n",
        "l = [] # 특수문자를 지운 문장들을 받아줄 리스트\n",
        "\n",
        "# with -> torch.no_grad()? => 특정한 객체가 생성이 되었을 때 with 구문이 끝나면 close 반환\n",
        "with open(\"./corpus.txt\", 'r', encoding='utf-8') as f:\n",
        "    # open(경로, 'r', encoding=인코딩방식): 파일을 읽어와줌 (텍스트파일)\n",
        "    # with .... -> 특정한 객체를 생성시키고, with 구문이 끝나면 해당 객체를 삭제 (반환)\n",
        "    # open () as f -> open을 통해 읽어들여온 파일을 f라는 이름에 변수에 할당\n",
        "    lines = f.read().split('\\n') # '\\n' = 엔터 = 개행문자\n",
        "    # 파일을 읽어온 다음에, 엔터(줄) 기준으로 쪼개줘라 -> 문장별로 리스트화\n",
        "    # lines = ['...', '...', '문장...']\n",
        "    for line in lines: # 문장\n",
        "        # 특수문자를 지우고 모든 글자를 소문자로 변경\n",
        "        txt = \"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "        l.append(txt)"
      ],
      "metadata": {
        "id": "a-aQlWAjAo6A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string # punctuation\n",
        "\n",
        "l = []\n",
        "\n",
        "with open('./corpus.txt', 'r', encoding='utf-8') as f:\n",
        "  # # print(f.read().split('\\n')) # 문자열 -> 엔터('\\n') 기준으로 분할해서 리스트화\n",
        "  # lines = f.read().split('\\n')\n",
        "  # for line in lines: # 반복문\n",
        "  #   txt = \"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "  #   l.append(txt)\n",
        "    l = [\"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "            for line in f.read().split('\\n')]\n",
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgpHtL8Vewu7",
        "outputId": "0acf3af5-9e9e-465c-890d-f38e6ced1db6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go\\t가',\n",
              " 'hi\\t안녕',\n",
              " 'run\\t뛰어',\n",
              " 'run\\t뛰어',\n",
              " 'who\\t누구',\n",
              " 'wow\\t우와',\n",
              " 'fire\\t쏴',\n",
              " 'help\\t도와줘',\n",
              " 'jump\\t점프',\n",
              " 'jump\\t점프해',\n",
              " 'wait\\t기다려',\n",
              " 'wait\\t잠깐',\n",
              " 'wait\\t기다려',\n",
              " 'begin\\t시작해',\n",
              " 'hello\\t안녕',\n",
              " 'i see\\t알았어',\n",
              " 'i try\\t시도해볼게',\n",
              " 'i won\\t내가 이겼어',\n",
              " 'oh no\\t아니 이런',\n",
              " 'relax\\t진정해',\n",
              " 'shoot\\t쏴',\n",
              " 'smile\\t웃어',\n",
              " 'attack\\t공격',\n",
              " 'attack\\t공격해',\n",
              " 'freeze\\t꼼짝마',\n",
              " 'get up\\t일어나',\n",
              " 'got it\\t알겠어',\n",
              " 'hug me\\t안아줘',\n",
              " 'i know\\t알아',\n",
              " 'i work\\t나 일해',\n",
              " 'listen\\t들어',\n",
              " 'no way\\t절대 아니야',\n",
              " 'no way\\t그럴리가',\n",
              " 'thanks\\t고마워',\n",
              " 'we try\\t우리는 시도할거야',\n",
              " 'we won\\t우리가 이겼어',\n",
              " 'why me\\t왜 나야',\n",
              " 'awesome\\t굉장해',\n",
              " 'be fair\\t공정하게 해',\n",
              " 'beat it\\t저리 가',\n",
              " 'call us\\t우리한테 연락해',\n",
              " 'come in\\t들어와',\n",
              " 'come on\\t어서',\n",
              " 'get out\\t나가',\n",
              " 'go away\\t저리 가',\n",
              " 'go away\\t저리 가',\n",
              " 'goodbye\\t안녕',\n",
              " 'he came\\t그가 왔어',\n",
              " 'he came\\t그 사람이 왔어',\n",
              " 'help me\\t도와줘',\n",
              " 'help me\\t도와줘',\n",
              " 'hit tom\\t톰을 때려',\n",
              " 'i agree\\t동의해',\n",
              " 'im sad\\t슬퍼',\n",
              " 'me too\\t나도',\n",
              " 'open up\\t열어',\n",
              " 'perfect\\t완벽해',\n",
              " 'show me\\t보여줘',\n",
              " 'shut up\\t시끄러워',\n",
              " 'skip it\\t건너뛰어',\n",
              " 'stop it\\t그만해',\n",
              " 'tell me\\t말해',\n",
              " 'tom won\\t톰이 이겼어',\n",
              " 'wake up\\t일어나',\n",
              " 'wash up\\t설거지 해',\n",
              " 'welcome\\t어서오세요',\n",
              " 'welcome\\t환영합니다',\n",
              " 'who won\\t누가 이겼어',\n",
              " 'why not\\t왜 안돼',\n",
              " 'cheer up\\t힘내',\n",
              " 'cool off\\t진정해',\n",
              " 'get lost\\t꺼져',\n",
              " 'go ahead\\t계속해',\n",
              " 'good job\\t잘했어',\n",
              " 'grab tom\\t톰을 잡아',\n",
              " 'how cute\\t귀엽잖아',\n",
              " 'how cute\\t이렇게 귀엽다니',\n",
              " 'how deep\\t얼마나 깊게',\n",
              " 'hurry up\\t서둘러',\n",
              " 'i forgot\\t잊어버렸어',\n",
              " 'im ugly\\t나는 못 생겼다',\n",
              " 'it hurts\\t아파',\n",
              " 'it works\\t동작하네',\n",
              " 'it works\\t작동하네',\n",
              " 'it works\\t되네',\n",
              " 'lets go\\t가자',\n",
              " 'look out\\t조심해',\n",
              " 'sit down\\t앉아',\n",
              " 'sit here\\t여기 앉아',\n",
              " 'speak up\\t크게 말해',\n",
              " 'stand up\\t일어서',\n",
              " 'tell tom\\t톰한테 말해',\n",
              " 'tell tom\\t톰에게 말해',\n",
              " 'they won\\t그들이 이겼어',\n",
              " 'they won\\t그 사람들이 이겼어',\n",
              " 'tom died\\t톰이 죽었어',\n",
              " 'tom left\\t톰이 떠났어',\n",
              " 'tom left\\t톰은 떠났어',\n",
              " 'tom lied\\t톰이 거짓말을 했어',\n",
              " 'tom lied\\t톰이 거짓말했어',\n",
              " 'tom lost\\t톰이 졌어',\n",
              " 'tom paid\\t톰이 지불했어',\n",
              " 'tom quit\\t톰이 그만둬',\n",
              " 'tom wept\\t톰이 눈물을 흘렸어',\n",
              " 'too late\\t너무 늦어',\n",
              " 'trust me\\t날 믿어',\n",
              " 'try hard\\t열심히 해',\n",
              " 'try some\\t좀 먹어봐',\n",
              " 'try this\\t이거 시도해봐',\n",
              " 'what for\\t뭐 하러',\n",
              " 'what fun\\t재밌잖아',\n",
              " 'what fun\\t이렇게 재미있을 수가',\n",
              " 'who died\\t누가 죽었어',\n",
              " 'who quit\\t누가 그만둬',\n",
              " 'answer me\\t대답해',\n",
              " 'birds fly\\t새가 날고 있네',\n",
              " 'calm down\\t진정해',\n",
              " 'come here\\t여기로 와',\n",
              " 'come home\\t집에 와',\n",
              " 'dogs bark\\t개가 짖네',\n",
              " 'dont lie\\t거짓말 하지 마',\n",
              " 'dont lie\\t거짓말 하지 마세요',\n",
              " 'fantastic\\t끝내주네',\n",
              " 'follow me\\t따라와',\n",
              " 'forget it\\t잊어버려',\n",
              " 'forget me\\t날 잊어',\n",
              " 'forget me\\t날 잊어버려',\n",
              " 'get ready\\t준비해',\n",
              " 'good luck\\t행운을 빌어',\n",
              " 'good luck\\t잘 되길 바라',\n",
              " 'grab this\\t저걸 움켜쥐어',\n",
              " 'hands off\\t손대지 마',\n",
              " 'he smiled\\t그 사람은 미소지었어',\n",
              " 'hold this\\t저걸 잡고 있어',\n",
              " 'how awful\\t끔찍해라',\n",
              " 'how awful\\t이렇게 끔찍할 수가',\n",
              " 'i fainted\\t나는 기절했어',\n",
              " 'i laughed\\t나는 웃었어',\n",
              " 'i promise\\t약속할게',\n",
              " 'im sorry\\t미안해',\n",
              " 'im sorry\\t미안해요',\n",
              " 'im sorry\\t죄송합니다',\n",
              " 'im sorry\\t유감입니다',\n",
              " 'it rained\\t비가 왔어',\n",
              " 'it rained\\t비가 내렸어',\n",
              " 'it snowed\\t눈이 왔어',\n",
              " 'it stinks\\t냄새나',\n",
              " 'its 745\\t지금 7시 45분이야',\n",
              " 'kill them\\t그들을 죽여라',\n",
              " 'leave now\\t당장 떠나',\n",
              " 'of course\\t물론이지',\n",
              " 'of course\\t물론이죠',\n",
              " 'oh please\\t아 제발',\n",
              " 'read this\\t이걸 읽어',\n",
              " 'say hello\\t인사해',\n",
              " 'see below\\t아래를 봐',\n",
              " 'seriously\\t진심이야',\n",
              " 'sit there\\t거기 앉아',\n",
              " 'sit tight\\t잠자코 있어',\n",
              " 'start now\\t당장 시작해',\n",
              " 'stay calm\\t침착해',\n",
              " 'stay here\\t여기에 있어',\n",
              " 'step back\\t물러서',\n",
              " 'stop here\\t여기서 멈춰',\n",
              " 'take care\\t주의하세요',\n",
              " 'take this\\t가져',\n",
              " 'take this\\t이거 가져',\n",
              " 'take this\\t이걸 가져',\n",
              " 'thank you\\t고마워',\n",
              " 'then what\\t그래서',\n",
              " 'they left\\t그들이 떠났어',\n",
              " 'they left\\t그 사람들은 떠났어',\n",
              " 'they left\\t그들은 떠났어',\n",
              " 'they lied\\t그들이 거짓말 쳤어',\n",
              " 'they lost\\t그들이 졌어',\n",
              " 'they lost\\t그 사람들이 졌어',\n",
              " 'tom cried\\t톰은 울었어',\n",
              " 'tom dozed\\t톰이 꾸벅 졸았어',\n",
              " 'tom drove\\t톰이 운전했어',\n",
              " 'tom knits\\t톰이 뜨개질 하고 있어',\n",
              " 'tom knows\\t톰은 알고 있어',\n",
              " 'try again\\t다시 한 번 해봐',\n",
              " 'turn left\\t왼쪽으로 돌아',\n",
              " 'turn left\\t좌회전해',\n",
              " 'wait here\\t여기서 기다려',\n",
              " 'watch out\\t조심해',\n",
              " 'we talked\\t우린 서로 얘기했어',\n",
              " 'we waited\\t우린 기다렸어',\n",
              " 'well done\\t잘 했어',\n",
              " 'who cares\\t누가 신경써',\n",
              " 'who knows\\t누가 알아',\n",
              " 'wonderful\\t멋져',\n",
              " 'you idiot\\t이 바보야',\n",
              " 'you tried\\t가상해',\n",
              " 'all aboard\\t모두 타',\n",
              " 'ask anyone\\t누군가에게 물어봐',\n",
              " 'be careful\\t조심해',\n",
              " 'be patient\\t참아',\n",
              " 'be patient\\t인내심을 가져',\n",
              " 'birds sing\\t새가 노래하네',\n",
              " 'bring wine\\t와인 가져와',\n",
              " 'bring wine\\t와인을 가져와',\n",
              " 'carry this\\t이거 날라',\n",
              " 'carry this\\t이거 운반해',\n",
              " 'check this\\t이거 확인해봐',\n",
              " 'choose one\\t하나 골라',\n",
              " 'come again\\t다시 와',\n",
              " 'come alone\\t혼자서 와',\n",
              " 'come along\\t따라와',\n",
              " 'come quick\\t빨리 와',\n",
              " 'definitely\\t절대로',\n",
              " 'dont talk\\t말하지 마',\n",
              " 'eat slowly\\t천천히 먹어',\n",
              " 'face facts\\t진실을 마주해',\n",
              " 'fire burns\\t불타네',\n",
              " 'follow him\\t저 사람을 따라가',\n",
              " 'forget tom\\t톰은 잊어버려',\n",
              " 'forget him\\t그 사람에 대해선 잊어 버려',\n",
              " 'forgive me\\t날 용서해',\n",
              " 'forgive us\\t우릴 용서해 줘',\n",
              " 'forgive us\\t우리를 용서해 줘',\n",
              " 'god exists\\t신은 존재해',\n",
              " 'he is nice\\t걔 괜찮아',\n",
              " 'he is tall\\t그 사람은 키가 커',\n",
              " 'hey relax\\t이봐 진정해',\n",
              " 'hold still\\t가만히 있으세요',\n",
              " 'hold still\\t가만히 있어',\n",
              " 'how lovely\\t어찌나 사랑스러운지',\n",
              " 'how tragic\\t너무 슬퍼',\n",
              " 'how tragic\\t이렇게나 슬프다니',\n",
              " 'hows work\\t일은 잘 되니',\n",
              " 'hows work\\t일은 어때',\n",
              " 'hurry back\\t빨리 와',\n",
              " 'i am human\\t나는 인간이야',\n",
              " 'i chuckled\\t난 킬킬 웃었어',\n",
              " 'i disagree\\t난 반대야',\n",
              " 'i envy him\\t그 사람이 부러워',\n",
              " 'i envy you\\t네가 부러워',\n",
              " 'i felt bad\\t난 기분이 나빴다',\n",
              " 'i remember\\t기억하고 있어',\n",
              " 'i want tom\\t난 톰을 원해',\n",
              " 'ignore tom\\t톰은 무시해',\n",
              " 'ignore him\\t그 사람은 무시해',\n",
              " 'is tom ill\\t톰은 아파',\n",
              " 'is that ok\\t괜찮은 거예요',\n",
              " 'it is warm\\t따뜻해',\n",
              " 'keep going\\t계속 가고 있어봐',\n",
              " 'keep quiet\\t조용히 해',\n",
              " 'keep still\\t계속 조용히 하고 있어봐',\n",
              " 'let me die\\t나 좀 죽게 내버려둬',\n",
              " 'look there\\t저기를 봐',\n",
              " 'love hurts\\t사랑은 아프다',\n",
              " 'mama cried\\t엄마가 울었어',\n",
              " 'mama cried\\t엄마는 울었어',\n",
              " 'never mind\\t신경쓰지마',\n",
              " 'no comment\\t할 말이 없어',\n",
              " 'no problem\\t문제 없어',\n",
              " 'once again\\t한 번 더',\n",
              " 'please sit\\t앉아 줘',\n",
              " 'please sit\\t제발 앉아',\n",
              " 'quiet down\\t조용히 해',\n",
              " 'sing along\\t따라 불러',\n",
              " 'start here\\t여기서 시작해',\n",
              " 'start over\\t다시 해',\n",
              " 'step aside\\t옆으로 비켜',\n",
              " 'stop lying\\t거짓말 그만 쳐',\n",
              " 'study hard\\t열심히 공부해',\n",
              " 'that hurts\\t아파',\n",
              " 'that hurts\\t그거 아프네',\n",
              " 'tom agreed\\t톰이 동의했어',\n",
              " 'tom cheats\\t톰이 사기 쳐',\n",
              " 'tom danced\\t톰은 춤을 췄어',\n",
              " 'tom drives\\t톰은 운전할 수 있어',\n",
              " 'tom failed\\t톰이 실패했어',\n",
              " 'tom forgot\\t톰이 잊었어',\n",
              " 'tom fought\\t톰이 싸웠어',\n",
              " 'tom gasped\\t톰이 헉 소리를 냈어',\n",
              " 'tom helped\\t톰이 도와줬어',\n",
              " 'tom jumped\\t톰이 점프했어',\n",
              " 'tom looked\\t톰이 쳐다봤어',\n",
              " 'tom moaned\\t톰이 끙끙댔어',\n",
              " 'tom nodded\\t톰이 고개를 끄덕였어',\n",
              " 'tom sighed\\t톰은 한숨 쉬었어',\n",
              " 'tom smiled\\t톰이 웃었어',\n",
              " 'tom snores\\t톰은 코를 골아',\n",
              " 'tom waited\\t톰은 기다렸어',\n",
              " 'tom yawned\\t톰이 하품했어',\n",
              " 'turn right\\t오른쪽으로 돌아',\n",
              " 'turn right\\t우회전해',\n",
              " 'you called\\t불렀어',\n",
              " 'you called\\t불렀니',\n",
              " 'you decide\\t네가 정해',\n",
              " 'anyone home\\t누구 집에 있어',\n",
              " 'anyone hurt\\t누군가 다쳤어',\n",
              " 'be cheerful\\t활기차게 해',\n",
              " 'be yourself\\t너 자신이 돼',\n",
              " 'be yourself\\t너답게 있어',\n",
              " 'boys do cry\\t남자애도 운다',\n",
              " 'check again\\t다시 확인해',\n",
              " 'come aboard\\t외국으로 와',\n",
              " 'come closer\\t가까이 와',\n",
              " 'come inside\\t안으로 들어와',\n",
              " 'finish this\\t이걸 끝내',\n",
              " 'get serious\\t진지하게 해',\n",
              " 'he chuckled\\t그 사람 킬킬 웃었어',\n",
              " 'he resigned\\t그 사람은 은퇴했어',\n",
              " 'how curious\\t정말 흥미로운데',\n",
              " 'how strange\\t참 이상하네',\n",
              " 'i dont lie\\t나는 거짓말 하지 않습니다',\n",
              " 'i dont lie\\t난 거짓말 안해',\n",
              " 'i dont lie\\t나는 거짓말 하지 않아',\n",
              " 'i exercised\\t난 운동했어',\n",
              " 'i overslept\\t나는 늦잠잤어',\n",
              " 'im nervous\\t긴장돼요',\n",
              " 'im nervous\\t떨려요',\n",
              " 'im shocked\\t충격이야',\n",
              " 'ignore that\\t그건 무시해',\n",
              " 'its a pity\\t안타까워요',\n",
              " 'its unfair\\t이건 불공평해',\n",
              " 'keep moving\\t계속 움직이고 있어봐',\n",
              " 'keep trying\\t계속 시도해',\n",
              " 'look around\\t둘러봐',\n",
              " 'money talks\\t돈이 최고야',\n",
              " 'my dog died\\t내 개는 죽었어',\n",
              " 'nice timing\\t타이밍 좋네',\n",
              " 'nice timing\\t좋은 타이밍이야',\n",
              " 'nobody came\\t아무도 안왔어',\n",
              " 'nobody died\\t아무도 안 죽었어',\n",
              " 'nobody died\\t아무도 죽지 않았어',\n",
              " 'nobody lied\\t아무도 거짓말을 안 했어',\n",
              " 'nobody lied\\t아무도 거짓말을 하지 않았어',\n",
              " 'plants grow\\t식물이 자란다',\n",
              " 'please sing\\t노래 부탁해',\n",
              " 'please stay\\t제발 남아 있어줘',\n",
              " 'please stop\\t제발 멈춰',\n",
              " 'release him\\t그 사람을 놓아 줘',\n",
              " 'release him\\t그를 놓아 줘',\n",
              " 'remember it\\t기억해',\n",
              " 'say goodbye\\t작별인사해',\n",
              " 'say nothing\\t아무 말도 하지 마',\n",
              " 'stop crying\\t그만 울어',\n",
              " 'stop moving\\t움직이지 마',\n",
              " 'they danced\\t그들은 춤췄어',\n",
              " 'they danced\\t그 사람들은 춤을 췄어',\n",
              " 'they hugged\\t그 사람들은 서로 포옹했어',\n",
              " 'they kissed\\t그 사람들 서로 키스했어',\n",
              " 'they obeyed\\t그 사람들은 복종했어',\n",
              " 'they smiled\\t그들이 웃었어',\n",
              " 'they smiled\\t그 사람들이 웃었어',\n",
              " 'tom blushed\\t톰의 얼굴이 빨개졌어',\n",
              " 'tom cheated\\t톰이 사기 쳤어',\n",
              " 'tom cheated\\t톰이 속임수를 썼어',\n",
              " 'tom clapped\\t톰이 박수쳤어',\n",
              " 'tom clapped\\t톰이 박수를 쳤어',\n",
              " 'tom coughed\\t톰은 기침했어',\n",
              " 'tom drowned\\t톰이 익사했어',\n",
              " 'tom drowned\\t톰이 물에 빠져 죽었어',\n",
              " 'tom escaped\\t톰이 빠져나갔어',\n",
              " 'tom escaped\\t톰이 빠져나왔어',\n",
              " 'tom exhaled\\t톰이 숨을 내쉬었어',\n",
              " 'tom exhaled\\t톰이 날숨을 쉬었어',\n",
              " 'tom fainted\\t톰이 기절했어',\n",
              " 'tom frowned\\t톰은 얼굴을 찡그렸어',\n",
              " 'tom giggled\\t톰이 피식 웃었어',\n",
              " 'tom giggled\\t톰이 낄낄거렸어',\n",
              " 'tom giggled\\t톰이 키득거렸어',\n",
              " 'tom grinned\\t톰이 씩 웃었어',\n",
              " 'tom grinned\\t톰이 씨익 웃었어',\n",
              " 'tom groaned\\t톰이 앓는 소리를 했어',\n",
              " 'tom inhaled\\t톰이 숨을 들이마셨어',\n",
              " 'tom kneeled\\t톰이 무릎을 꿇었어',\n",
              " 'tom laughed\\t톰이 웃었어',\n",
              " 'toms lying\\t톰은 거짓말 치고 있어',\n",
              " 'turn around\\t돌아',\n",
              " 'walk slowly\\t천천히 걸어',\n",
              " 'we promised\\t우린 약속했어',\n",
              " 'we remember\\t우린 기억하고 있어',\n",
              " 'we survived\\t우리가 살아남았어',\n",
              " 'whats that\\t저건 뭐야',\n",
              " 'work slowly\\t쉬엄쉬엄 일해',\n",
              " 'youre mine\\t넌 내 거야',\n",
              " 'youre mine\\t당신은 나의 것입니다',\n",
              " 'anybody here\\t누구 있어',\n",
              " 'anybody home\\t누구 집에 있어',\n",
              " 'anybody home\\t집에 누군가 있어',\n",
              " 'anybody hurt\\t누가 다쳤어',\n",
              " 'anything new\\t새로운 것이라도 있어',\n",
              " 'be realistic\\t현실적으로 생각해',\n",
              " 'beef please\\t쇠고기요',\n",
              " 'blood is red\\t피는 붉다',\n",
              " 'can i go now\\t이제 가도 되나요',\n",
              " 'come forward\\t앞쪽으로 와',\n",
              " 'come quickly\\t빨리 와',\n",
              " 'come quickly\\t빨리 오세요',\n",
              " 'dont eat it\\t먹지 마',\n",
              " 'drive faster\\t빨리 운전해',\n",
              " 'examine them\\t이것들 조사해봐',\n",
              " 'examine this\\t이걸 조사해봐',\n",
              " 'fish please\\t물고기요',\n",
              " 'ghosts exist\\t유령은 존재해',\n",
              " 'grab a spoon\\t숟가락 집어',\n",
              " 'he succeeded\\t그 사람이 성공했어',\n",
              " 'hes too old\\t그 사람은 너무 늙었어',\n",
              " 'how annoying\\t이렇게 짜증날 수가',\n",
              " 'how annoying\\t이렇게나 짜증나다니',\n",
              " 'how arrogant\\t이렇게나 건방지다니',\n",
              " 'how horrible\\t이렇게나 끔찍하다니',\n",
              " 'i apologized\\t난 사과했어',\n",
              " 'i dont know\\t나는 몰라요',\n",
              " 'i hate liars\\t난 거짓말쟁이가 싫어',\n",
              " 'i need money\\t돈이 필요해요',\n",
              " 'i understand\\t이해해',\n",
              " 'i understood\\t이해했어',\n",
              " 'im addicted\\t난 중독자야',\n",
              " 'im bleeding\\t나 피나',\n",
              " 'is that okay\\t괜찮은 거예요',\n",
              " 'is this mine\\t이거 내꺼니',\n",
              " 'is this wine\\t이게 와인이야',\n",
              " 'itll be hot\\t더워질거야',\n",
              " 'its suicide\\t자살입니다',\n",
              " 'its too old\\t그건 너무 낡았어',\n",
              " 'its too old\\t그건 너무 오래되었어',\n",
              " 'just keep it\\t그냥 그거 가져',\n",
              " 'keep dancing\\t계속 춤춰',\n",
              " 'keep dancing\\t계속 춤추고 있어봐',\n",
              " 'keep digging\\t계속 땅 파고 있어봐',\n",
              " 'keep digging\\t계속 땅 파',\n",
              " 'keep driving\\t계속 운전하고 있어봐',\n",
              " 'keep focused\\t계속 집중하고 있어봐',\n",
              " 'keep looking\\t계속 보고 있어봐',\n",
              " 'keep reading\\t계속 읽어',\n",
              " 'keep singing\\t계속 노래하고 있어',\n",
              " 'keep singing\\t계속 노래해',\n",
              " 'keep smiling\\t계속 미소지어',\n",
              " 'keep smiling\\t계속 웃어',\n",
              " 'keep smiling\\t계속 웃고 있어봐',\n",
              " 'keep talking\\t계속 말해',\n",
              " 'keep talking\\t계속 말하고 있어봐',\n",
              " 'move quietly\\t조용히 움직여',\n",
              " 'nobody asked\\t아무도 안 물어봤어',\n",
              " 'nobody knows\\t아무도 몰라',\n",
              " 'please hurry\\t서둘러 주세요',\n",
              " 'please leave\\t제발 떠나 줘',\n",
              " 'please relax\\t제발 진정해',\n",
              " 'please smile\\t웃어줘',\n",
              " 'she was busy\\t그는 바빴다',\n",
              " 'someone came\\t누군가 왔어',\n",
              " 'stop reading\\t그만 읽어',\n",
              " 'stop smoking\\t담배 피지 마',\n",
              " 'stop staring\\t그만 쳐다봐',\n",
              " 'stop talking\\t그만 말해',\n",
              " 'stop whining\\t그만 흐느껴',\n",
              " 'stop yelling\\t그만 소리쳐',\n",
              " 'they escaped\\t그 사람들은 도망 쳤어',\n",
              " 'they laughed\\t그 사람들 웃었어',\n",
              " 'they refused\\t그 사람들은 거절했어',\n",
              " 'they relaxed\\t그 사람들은 진정했어',\n",
              " 'tom answered\\t톰이 대답했어',\n",
              " 'tom approved\\t톰이 승낙했어',\n",
              " 'tom chuckled\\t톰이 싱긋 웃었어',\n",
              " 'tom chuckled\\t톰이 빙그레 웃었어',\n",
              " 'tom enlisted\\t톰이 입대했어',\n",
              " 'tom finished\\t톰이 끝냈어',\n",
              " 'tom flinched\\t톰이 움찔했어',\n",
              " 'tom grumbled\\t톰이 궁시렁거렸어',\n",
              " 'tom grumbled\\t톰이 투덜거렸어',\n",
              " 'tom insisted\\t톰이 주장했어',\n",
              " 'tom is eager\\t톰은 열성적이야',\n",
              " 'tom is quick\\t톰은 빨라',\n",
              " 'tom is quick\\t톰은 날렵해',\n",
              " 'tom is silly\\t톰은 실없어',\n",
              " 'tom is sober\\t톰은 제정신이야',\n",
              " 'tom is sober\\t톰은 멀쩡해',\n",
              " 'tom listened\\t톰이 듣고 있었어',\n",
              " 'tom shrugged\\t톰이 어깨를 으쓱했어',\n",
              " 'tom whistled\\t톰이 휘파람 불었어',\n",
              " 'unbelievable\\t설마',\n",
              " 'we apologize\\t우리가 사과할게',\n",
              " 'we dont lie\\t우리는 거짓말을 하지 않아요',\n",
              " 'we dont lie\\t우린 거짓말 안해',\n",
              " 'we overslept\\t우린 늦잠잤어',\n",
              " 'we succeeded\\t우린 성공했어',\n",
              " 'we succeeded\\t우리는 성공했어',\n",
              " 'were inside\\t우리 안에 들어와 있어',\n",
              " 'were inside\\t우린 안에 있어요',\n",
              " 'welcome back\\t어서 와',\n",
              " 'welcome home\\t어서와',\n",
              " 'what is that\\t저것은 무엇입니까',\n",
              " 'any questions\\t질문 있어',\n",
              " 'any questions\\t아무 질문이라도',\n",
              " 'can i ask why\\t이유를 물어봐도 돼',\n",
              " 'cats are cute\\t고양이는 귀여워',\n",
              " 'come tomorrow\\t내일 와',\n",
              " 'eat something\\t뭔가 먹어',\n",
              " 'everyone dies\\t누구나 죽어',\n",
              " 'flowers bloom\\t꽃이 피네',\n",
              " 'grab the rope\\t로프를 잡으세요',\n",
              " 'he is too old\\t그 사람은 너무 늙었어',\n",
              " 'hes autistic\\t그 사람은 자폐성향이 있어',\n",
              " 'how beautiful\\t이렇게나 아름다울 수가',\n",
              " 'how wonderful\\t이렇게 멋질 수가',\n",
              " 'i am homesick\\t나 향수병 걸렸어',\n",
              " 'i cant sleep\\t잠이 와',\n",
              " 'i feel guilty\\t죄책감이 들어',\n",
              " 'i feel lonely\\t외로워',\n",
              " 'i got engaged\\t나 약혼했어',\n",
              " 'i hate myself\\t나는 내 자신이 싫어',\n",
              " 'i like horses\\t나는 말을 좋아해',\n",
              " 'i like winter\\t난 겨울이 좋아',\n",
              " 'i miss my cat\\t난 내 고양이가 그리워',\n",
              " 'i smell blood\\t피 냄새가 납니다',\n",
              " 'i use firefox\\t나는 파이어폭스를 사용해',\n",
              " 'i want to die\\t죽고 싶어요',\n",
              " 'i want to die\\t죽고 싶어',\n",
              " 'ill kill him\\t나는 그를 죽일 것이다',\n",
              " 'im at school\\t난 학교에 있어',\n",
              " 'im depressed\\t우울해',\n",
              " 'im religious\\t난 신앙이 있어',\n",
              " 'is my time up\\t내 시간 끝났어',\n",
              " 'is that blood\\t그거 피야',\n",
              " 'keep fighting\\t계속 싸워',\n",
              " 'my head hurts\\t머리가 아파요',\n",
              " 'my names tom\\t제 이름은 톰입니다',\n",
              " 'please listen\\t제발 좀 들어',\n",
              " 'quiet please\\t조용히 해줘',\n",
              " 'quit gambling\\t도박 그만해',\n",
              " 'say something\\t아무 말이나 해봐',\n",
              " 'she overslept\\t그 사람은 늦잠잤어',\n",
              " 'she was naive\\t그는 순진했다',\n",
              " 'she was young\\t그는 어렸다',\n",
              " 'show yourself\\t너의 모습을 드러내',\n",
              " 'show yourself\\t네 모습을 보여줘',\n",
              " 'speak clearly\\t분명하게 말해',\n",
              " 'start singing\\t노래 시작해',\n",
              " 'stay positive\\t긍정적으로 있어',\n",
              " 'stop babbling\\t그만 떠들어',\n",
              " 'stop fighting\\t그만 싸워',\n",
              " 'stop laughing\\t그만 웃어',\n",
              " 'stop shooting\\t총 그만 쏴',\n",
              " 'stop worrying\\t그만 걱정해',\n",
              " 'stop worrying\\t걱정 그만해',\n",
              " 'thanks anyway\\t어쨌든 고마워',\n",
              " 'thats my cat\\t저거 내 고양이야',\n",
              " 'thats my dog\\t이건 내 강아지야',\n",
              " 'thats not it\\t아니야',\n",
              " 'they screamed\\t그 사람들은 비명을 질렀어',\n",
              " 'tom confessed\\t톰이 자백했어',\n",
              " 'tom graduated\\t톰이 졸업했어',\n",
              " 'tom has a cat\\t톰은 고양이를 키우고 있어',\n",
              " 'tom hesitated\\t톰이 주저했어',\n",
              " 'tom hesitated\\t톰이 머뭇거렸어',\n",
              " 'tom is honest\\t톰은 정직하다',\n",
              " 'tom overslept\\t톰은 늦잠잤어',\n",
              " 'watch closely\\t가까이서 봐',\n",
              " 'we can buy it\\t이건 우리가 살 수 있어',\n",
              " 'we understand\\t우린 이해해',\n",
              " 'we want peace\\t우리는 평화를 원합니다',\n",
              " 'were too old\\t우린 너무 늙었어',\n",
              " 'you work hard\\t너는 열심히 일을 한다',\n",
              " 'apples are red\\t사과는 빨개',\n",
              " 'autumn is here\\t가을이 되었습니다',\n",
              " 'autumn is here\\t가을이 왔어요',\n",
              " 'can i help you\\t제가 좀 도와 드릴까요',\n",
              " 'cats are great\\t고양이들은 멋져',\n",
              " 'do you hear me\\t제 말이 들리세요',\n",
              " 'everybody knew\\t모두가 알고 있었어',\n",
              " 'everybody left\\t모두 떠났어',\n",
              " 'everybody lies\\t누구나 거짓말 해',\n",
              " 'everyone stood\\t모두 일어섰어',\n",
              " 'everyone stood\\t모두가 일어섰어',\n",
              " 'happy new year\\t새해 복 많이 받아',\n",
              " 'he was hard up\\t그는 돈에 쪼들리고 있었다',\n",
              " 'hello everyone\\t모두들 안녕',\n",
              " 'i dont buy it\\t못 믿어',\n",
              " 'i feel relaxed\\t마음이 편안하다',\n",
              " 'i like reading\\t독서를 좋아합니다',\n",
              " 'i like to work\\t나는 일하기 좋아해',\n",
              " 'i love lasagna\\t저는 라자냐를 좋아해요',\n",
              " 'i love my home\\t난 내 집이 좋아',\n",
              " 'i study korean\\t한국말을 공부합니다',\n",
              " 'ill find them\\t내가 찾아 볼게',\n",
              " 'im very sorry\\t정말 미안해',\n",
              " 'im very sorry\\t정말 죄송합니다',\n",
              " 'its not funny\\t안 재밌어',\n",
              " 'its so simple\\t정말 간단해',\n",
              " 'keep tom there\\t톰은 여기에 두세요',\n",
              " 'keep listening\\t계속 들어',\n",
              " 'keep searching\\t계속 찾아봐',\n",
              " 'keep searching\\t계속 찾고 있어봐',\n",
              " 'louder please\\t좀더 큰소리로 부탁해',\n",
              " 'my name is tom\\t제 이름은 톰입니다',\n",
              " 'only god knows\\t신만이 아실 것입니다',\n",
              " 'please proceed\\t진행해줘',\n",
              " 'read this book\\t이 책 읽어',\n",
              " 'read this book\\t이 책을 읽으세요',\n",
              " 'science is fun\\t과학은 재밌어',\n",
              " 'smoking stinks\\t담배 냄새 나',\n",
              " 'someone called\\t누군가 불렀어',\n",
              " 'sorry im late\\t늦어서 미안해',\n",
              " 'stop grumbling\\t그만 투덜거려',\n",
              " 'tell everybody\\t모두한테 말해',\n",
              " 'tell everybody\\t모두에게 말해',\n",
              " 'thats suicide\\t그것은 자살입니다',\n",
              " 'the cat meowed\\t고양이가 야옹하고 울었어',\n",
              " 'the ice melted\\t얼음이 녹았어',\n",
              " 'they quarreled\\t그사람들 싸웠어',\n",
              " 'ticket please\\t티켓 부탁해',\n",
              " 'tom apologized\\t톰이 사과했어',\n",
              " 'tom hates cats\\t톰은 고양이를 싫어해',\n",
              " 'tom is abusive\\t톰은 폭력적이야',\n",
              " 'tom is awesome\\t톰은 정말 멋져',\n",
              " 'tom is too old\\t톰은 너무 늙었어',\n",
              " 'tom went there\\t톰이 거기로 갔어',\n",
              " 'watch yourself\\t조심해',\n",
              " 'we need change\\t우린 변화가 필요해',\n",
              " 'we surrendered\\t우린 항복했어',\n",
              " 'we volunteered\\t우린 자원해서 했어',\n",
              " 'you look smart\\t너 똑똑해 보여',\n",
              " 'you scared tom\\t넌 톰을 무섭게 했어',\n",
              " 'youre too old\\t넌 너무 늙었어',\n",
              " 'behave yourself\\t처신 잘해',\n",
              " 'boil some water\\t물 좀 끓여',\n",
              " 'can you help me\\t저를 좀 도와 주실래요',\n",
              " 'congratulations\\t축하해',\n",
              " 'congratulations\\t축하해요',\n",
              " 'did tom do that\\t톰이 그랬대',\n",
              " 'did tom look ok\\t톰은 괜찮아 보였어',\n",
              " 'do you like rap\\t랩 좋아해요',\n",
              " 'do you like rap\\t랩 좋아해',\n",
              " 'dont lie to me\\t내게 거짓말 하지 마',\n",
              " 'dont lie to me\\t제게 거짓말 하지 마세요',\n",
              " 'dont lie to us\\t우리에게 거짓말 하지 마',\n",
              " 'dont lie to us\\t저희에게 거짓말 하지 마세요',\n",
              " 'drive carefully\\t운전 조심하세요',\n",
              " 'drive carefully\\t운전 조심해',\n",
              " 'everybody knows\\t모두가 알고 있어',\n",
              " 'everyone dreams\\t누구나 꿈을 꿔',\n",
              " 'everyone looked\\t모두들 쳐다봤어',\n",
              " 'everyone prayed\\t모두 기도했어',\n",
              " 'everyone prayed\\t모두들 기도했어',\n",
              " 'everyone smiled\\t모두들 미소지었어',\n",
              " 'everyone waited\\t모두들 기다렸어',\n",
              " 'green suits you\\t초록색이 너한테 어울려',\n",
              " 'have a good day\\t좋은하루 되세요',\n",
              " 'he came at dawn\\t그는 새벽에 왔다',\n",
              " 'he is depressed\\t그는 우울하다',\n",
              " 'he loves trains\\t그는 열차를 좋아한다',\n",
              " 'how fascinating\\t이렇게 매력적일 수가',\n",
              " 'how fascinating\\t이렇게나 매력적이라니',\n",
              " 'how interesting\\t이렇게나 흥미롭다니',\n",
              " 'i caught a cold\\t감기 걸렸어',\n",
              " 'i caught a cold\\t감기에 걸렸어',\n",
              " 'i didnt scream\\t난 비명을 지르지 않았어',\n",
              " 'i felt excluded\\t난 소외감을 느꼈어',\n",
              " 'i hate funerals\\t장례식이 싫어',\n",
              " 'i hate my voice\\t나는 내 목소리가 싫다',\n",
              " 'i know tom well\\t나는 톰을 잘 안다',\n",
              " 'i learned a lot\\t나는 많이 배웠어',\n",
              " 'i misunderstood\\t난 오해했어',\n",
              " 'i was convicted\\t나는 유죄 판결을 받았다',\n",
              " 'i work at a zoo\\t나는 동물원에서 일해',\n",
              " 'im embarrassed\\t창피해',\n",
              " 'im heartbroken\\t제 마음이 아파요',\n",
              " 'im not sulking\\t나 삐친 거 아니야',\n",
              " 'is this ethical\\t이거 윤리적이야',\n",
              " 'it doesnt hurt\\t아프지 않아',\n",
              " 'its very humid\\t상당히 습하다',\n",
              " 'keep the change\\t잔돈은 가지세요',\n",
              " 'might i come in\\t내가 들어와도 될까',\n",
              " 'my blood boiled\\t내 피가 끓었다',\n",
              " 'my cat is black\\t내 고양이는 검은색 고양이야',\n",
              " 'please continue\\t계속 해줘',\n",
              " 'she disappeared\\t그 사람이 사라졌어',\n",
              " 'she disappeared\\t그가 사라졌어',\n",
              " 'she was my boss\\t그는 내 상사였다',\n",
              " 'shes a trainee\\t그녀는 연습생이다',\n",
              " 'shes depressed\\t그녀는 우울하다',\n",
              " 'someone coughed\\t누군가 기침했어',\n",
              " 'sorry im late\\t늦어서 미안합니다',\n",
              " 'that was stupid\\t그건 멍청했어',\n",
              " 'thats a pencil\\t그거 연필이야',\n",
              " 'thats horrible\\t끔찍하네',\n",
              " 'the bag is full\\t가방이 꽉 찼습니다',\n",
              " 'the cat is lazy\\t고양이는 게을러',\n",
              " 'there was blood\\t피가 있었다',\n",
              " 'they believe me\\t그 사람들은 날 믿어',\n",
              " 'they want peace\\t그들은 평화를 원한다',\n",
              " 'they were naive\\t걔들이 순진했어',\n",
              " 'this is suicide\\t이것은 자살입니다',\n",
              " 'tom didnt vote\\t톰은 투표 안 했어',\n",
              " 'tom disappeared\\t톰이 사라졌어',\n",
              " 'tom got retired\\t톰은 은퇴했어',\n",
              " 'tom is a runner\\t톰은 달리기 선수야',\n",
              " 'tom volunteered\\t톰이 자웠했어',\n",
              " 'tom was too old\\t톰은 너무 늙었어',\n",
              " 'watch carefully\\t잘 봐',\n",
              " 'we need experts\\t우리에겐 전문가가 필요해',\n",
              " 'what time is it\\t몇시 입니까',\n",
              " 'why do we dream\\t왜 우리는 꿈을 꿔',\n",
              " 'write something\\t뭔가 써',\n",
              " 'youre a genius\\t너 천재구나',\n",
              " 'are you busy now\\t지금 바빠',\n",
              " 'are you in there\\t너 거기 있어',\n",
              " 'are you sleeping\\t자고 있어',\n",
              " 'are you studying\\t공부하고 계십니까',\n",
              " 'call this number\\t이 번호로 전화해',\n",
              " 'choose carefully\\t신중하게 골라',\n",
              " 'come immediately\\t즉시 와',\n",
              " 'do you like fish\\t생선 좋아해요',\n",
              " 'do you like fish\\t생선 좋아해',\n",
              " 'do you like fish\\t물고기 좋아하나요',\n",
              " 'do you like fish\\t물고기 좋아해',\n",
              " 'drink some water\\t물 좀 마셔',\n",
              " 'everybody smiled\\t모두 웃었어',\n",
              " 'everybody smiled\\t모두 미소지었어',\n",
              " 'everyone changes\\t누구나 바뀌어',\n",
              " 'everyone laughed\\t모두가 웃었어',\n",
              " 'give me my sword\\t내 검을 줘',\n",
              " 'give me the file\\t나한테 파일 줘',\n",
              " 'he loves singing\\t그는 노래하기를 좋아한다',\n",
              " 'her hair is long\\t그녀의 머리카락은 길어',\n",
              " 'her hair is long\\t그녀의 머리카락은 길다',\n",
              " 'here is the bill\\t여기 계산서 입니다',\n",
              " 'his face was red\\t그 사람 얼굴은 빨갰어',\n",
              " 'how embarrassing\\t이렇게 창피할 수가',\n",
              " 'i bought a horse\\t난 말 한 마리를 샀어',\n",
              " 'i dont envy you\\t난 네가 부럽지 않아',\n",
              " 'i felt very safe\\t나는 매우 안전하다고 느꼈다',\n",
              " 'i like languages\\t언어를 좋아합니다',\n",
              " 'i like languages\\t언어가 좋습니다',\n",
              " 'i lost my wallet\\t지갑을 잃어버렸어',\n",
              " 'i may be too old\\t난 너무 늙었을지도 몰라',\n",
              " 'i may be too old\\t난 아마 너무 늙었어',\n",
              " 'i missed the bus\\t버스를 놓쳤어요',\n",
              " 'i said im sorry\\t미안하다고 했잖아',\n",
              " 'i said im sorry\\t미안하다고 했잖아요',\n",
              " 'im dead serious\\t난 절대 농담하는게 아냐',\n",
              " 'im disorganized\\t나는 체계적이지 못하다',\n",
              " 'im not suicidal\\t나는 자살하고 싶지 않다',\n",
              " 'im your teacher\\t난 네 선생이다',\n",
              " 'is that a spider\\t이거 거미야',\n",
              " 'is the bank open\\t은행 문 열었어요',\n",
              " 'is the bank open\\t은행 해요',\n",
              " 'it could be true\\t진짜일 수도 있어',\n",
              " 'it was a mistake\\t그건 실수였어',\n",
              " 'its a full moon\\t보름달이야',\n",
              " 'its nearly dark\\t거의 어두워지고 있어',\n",
              " 'its really loud\\t정말 시끄럽네',\n",
              " 'listen carefully\\t주의깊게 들어',\n",
              " 'look at the moon\\t달을 봐',\n",
              " 'nobodys perfect\\t그 누구도 완벽하지 않는다',\n",
              " 'nobodys perfect\\t완벽한 사람은 없어',\n",
              " 'nothing happened\\t아무일도 없었어',\n",
              " 'she is beautiful\\t그녀는 아름답다',\n",
              " 'somebody laughed\\t누군가 웃었어',\n",
              " 'someone has died\\t누군가 죽었어',\n",
              " 'someone screamed\\t누군가 비명을 질렀어',\n",
              " 'stop apologizing\\t그만 사과해',\n",
              " 'stop complaining\\t그만 불평해',\n",
              " 'that is a pencil\\t그거 연필이야',\n",
              " 'that made me cry\\t그것 때문에 울었다',\n",
              " 'thats very kind\\t참 친절하구나',\n",
              " 'the kids love it\\t아이들이 좋아해',\n",
              " 'there arent any\\t없다',\n",
              " 'they disappeared\\t그들은 사라졌어',\n",
              " 'they disappeared\\t그 사람들은 사라졌어',\n",
              " 'theyre amateurs\\t걔네 초짜야',\n",
              " 'think about this\\t생각 좀 해봐',\n",
              " 'this is a flower\\t이건 꽃이야',\n",
              " 'this seats free\\t이 자리 비었어',\n",
              " 'tom has kids now\\t톰한텐 이제 애들이 있어',\n",
              " 'tom is a manager\\t톰은 관리자야',\n",
              " 'tom is a nominee\\t톰은 후보야',\n",
              " 'tom is an orphan\\t톰은 고아야',\n",
              " 'tom is fantastic\\t톰은 환상적이야',\n",
              " 'tom is fast too\\t톰도 빨라',\n",
              " 'tom is real busy\\t톰은 진짜 바빠',\n",
              " 'tom is worked up\\t톰은 흥분해 있다',\n",
              " 'tom isnt a liar\\t톰은 거짓말쟁이가 아니야',\n",
              " 'tom isnt skinny\\t톰은 마르지 않았다',\n",
              " 'watch me closely\\t나를 가까이서 봐',\n",
              " 'water the plants\\t식물에 물을 주세요',\n",
              " 'we cant give up\\t우린 포기할 수 없어',\n",
              " 'we cant give up\\t포기할 수 없어요',\n",
              " 'wed been warned\\t우린 경고 받았었어',\n",
              " 'what do you like\\t무엇을 좋아하세요',\n",
              " 'what do you like\\t뭘 좋아해',\n",
              " 'what do you like\\t뭐가 좋아',\n",
              " 'where is the cat\\t고양이는 어딨어',\n",
              " 'you made tom cry\\t네가 톰을 울렸어',\n",
              " 'youll regret it\\t너 후회할거야',\n",
              " 'youre shivering\\t너 떨고 있네',\n",
              " 'your plan failed\\t네 계획은 실패했어',\n",
              " 'admission is free\\t입장은 무료야',\n",
              " 'can i borrow this\\t이거 좀 빌려 줄래',\n",
              " 'can you handle it\\t잘 해낼 수 있니',\n",
              " 'champagne please\\t샴폐인 좀',\n",
              " 'champagne please\\t샴폐인 부탁해',\n",
              " 'champagne please\\t샴폐인 주세요',\n",
              " 'come and see this\\t와서 이것좀 봐',\n",
              " 'do you have proof\\t증거 있어',\n",
              " 'do you work alone\\t혼자서 일해',\n",
              " 'does tom like you\\t톰은 너 좋아해',\n",
              " 'dont be so silly\\t실없게 굴지마',\n",
              " 'dont even try it\\t시도조차 하지마',\n",
              " 'everybody laughed\\t전부 웃었어',\n",
              " 'everyone screamed\\t모두 비명을 질렀어',\n",
              " 'everyone survived\\t모두 살아남았어',\n",
              " 'everyone survived\\t모두가 살아남았어',\n",
              " 'everyone survived\\t모두들 살아남았어',\n",
              " 'exercise outdoors\\t밖에서 운동해',\n",
              " 'god bless you all\\t신의 가호가 있길',\n",
              " 'goodnight mother\\t엄마 잘자',\n",
              " 'he died yesterday\\t그는 어제 죽었어',\n",
              " 'her nails are red\\t그 사람의 손톱은 빨간색이야',\n",
              " 'i believe in love\\t난 사랑을 믿는다',\n",
              " 'i can go tomorrow\\t난 내일 갈 수 있어',\n",
              " 'i cant walk fast\\t난 빠르게 걸을 수 없어',\n",
              " 'i cant walk fast\\t난 빠른 걸음을 할 수 없어',\n",
              " 'i cant walk fast\\t난 빠른 걸음은 할 수 없어',\n",
              " 'i doubted my eyes\\t난 내 눈을 의심했어',\n",
              " 'i feel really sad\\t나 정말 슬퍼',\n",
              " 'i got up at seven\\t난 일곱 시에 일어났어',\n",
              " 'i have a headache\\t머리가 아파요',\n",
              " 'i heard tom laugh\\t난 톰이 웃는 걸 들었어',\n",
              " 'i heard tom shout\\t난 톰이 소리지르는 걸 들었어',\n",
              " 'i kicked tom hard\\t내가 톰을 세게 걷어찼어',\n",
              " 'i like watermelon\\t난 수박 좋아해',\n",
              " 'i met tom outside\\t난 톰을 밖에서 봤어',\n",
              " 'i saw tom waiting\\t톰이 기다리는 걸 봤어',\n",
              " 'i saw tom working\\t난 톰이 일하는 걸 봤어',\n",
              " 'i sent tom a text\\t난 톰한테 문자 보냈어',\n",
              " 'i shook tom awake\\t난 톰을 흔들어 깨웠어',\n",
              " 'i stole toms car\\t내가 톰의 자동차를 훔쳤어',\n",
              " 'i taught tom golf\\t난 톰한테 골프를 가르쳤어',\n",
              " 'i texted tom back\\t난 톰한테 답장했어',\n",
              " 'i told tom to lie\\t난 톰한테 거짓말 하라고 말했어',\n",
              " 'i used toms idea\\t톰의 아이디어를 썼어',\n",
              " 'i used to be poor\\t난 가난했었어',\n",
              " 'i warned you once\\t난 널 한 번 경고했어',\n",
              " 'i was intoxicated\\t술 취했었다',\n",
              " 'i was quite lucky\\t난 꽤 운이 좋았었어',\n",
              " 'i watched tom eat\\t톰이 먹는 걸 지켜봤어',\n",
              " 'i watched a movie\\t나는 영화를 봤어',\n",
              " 'i wont permit it\\t나는 그것을 허락하지 않을거야',\n",
              " 'id be devastated\\t난 피폐해질 거야',\n",
              " 'ill go by subway\\t지하철로 갈게',\n",
              " 'im a human being\\t난 인간이야',\n",
              " 'im a patient man\\t난 참을성이 있는 남자야',\n",
              " 'im a simple girl\\t저는 단순한 소녀에요',\n",
              " 'im extremely shy\\t난 극히 낯을 가려',\n",
              " 'im in charge now\\t이제 내가 책임을 지고 있다',\n",
              " 'im not an addict\\t난 중독자 아니야',\n",
              " 'ive fed the fish\\t물고기한테 먹이를 줬어',\n",
              " 'its a dictionary\\t이것은 사전이다',\n",
              " 'its just a dream\\t그냥 꿈일 뿐이야',\n",
              " 'leave me in peace\\t저를 내버려 두세요',\n",
              " 'lets play a game\\t게임 한판 하자',\n",
              " 'life is too short\\t삶은 너무 짧네',\n",
              " 'look at the clock\\t시계를 보세요',\n",
              " 'may god bless you\\t신께서 당신을 축복하시길',\n",
              " 'no music no life\\t음악이 없으면 인생도 없어',\n",
              " 'no one was killed\\t아무도 죽지 않았어',\n",
              " 'nobody is perfect\\t그 누구도 완벽하지 않는다',\n",
              " 'please reconsider\\t다시 한 번 고려해줘',\n",
              " 'save it for later\\t나중을 위해 아껴둬',\n",
              " 'she isnt married\\t그 사람은 아직 결혼하지 않았어',\n",
              " 'she isnt married\\t그 사람은 미혼이야',\n",
              " 'she isnt married\\t그는 결혼하지 않았다',\n",
              " 'she isnt married\\t그는 미혼이다',\n",
              " 'she loves singing\\t그녀는 노래하기를 좋아한다',\n",
              " 'something changed\\t무언가 바뀌었어',\n",
              " 'stop overreacting\\t과민반응 그만해',\n",
              " 'take the medicine\\t그 약을 먹으세요',\n",
              " 'they got addicted\\t그 사람들 중독되었어',\n",
              " 'theyre all liars\\t너희 모두 거짓말쟁이다',\n",
              " 'tom hates spiders\\t톰은 거미를 싫어해',\n",
              " 'tom is a bit late\\t톰이 좀 늦네',\n",
              " 'tom is not a liar\\t톰은 거짓말쟁이가 아니야',\n",
              " 'tom made mary mad\\t톰은 메리를 화나게 했어',\n",
              " 'tom moves quickly\\t톰은 빨리 움직이네',\n",
              " 'tom seemed sleepy\\t톰은 졸려 보였어',\n",
              " 'tom vomited blood\\t톰은 피를 토했다',\n",
              " 'tom won the match\\t톰은 경기에서 이겼다',\n",
              " 'turn on the radio\\t라디오를 켜세요',\n",
              " 'we only take cash\\t우리는 현금만 가져갈 거야',\n",
              " 'what a tacky idea\\t참으로 조잡한 발상이네',\n",
              " 'whats this smell\\t이거 무슨 냄새지',\n",
              " 'where is the bank\\t그 은행은 어디에 있어요',\n",
              " 'where is the bank\\t그 은행은 어디 있어',\n",
              " 'why are you lying\\t왜 거짓말 하는거야',\n",
              " 'you are beautiful\\t아름다우시네요',\n",
              " 'you can have mine\\t너는 내 것을 가질 수 있다',\n",
              " 'youll get lonely\\t넌 외로워질거야',\n",
              " 'youre both liars\\t너희 둘 다 거짓말쟁이다',\n",
              " 'your lips are red\\t네 입술 빨개',\n",
              " 'a cat is not human\\t고양이는 인간이 아니야',\n",
              " 'ask tom for advice\\t톰에게 조언을 구해봐',\n",
              " 'can i see this one\\t이것 좀 보여주실래요',\n",
              " 'dont be so greedy\\t그렇게 욕심부리지 마',\n",
              " 'dont get me wrong\\t오해하지 마',\n",
              " 'drink to my health\\t건강을 위해 건배',\n",
              " 'everyone hesitated\\t모두 주저했어',\n",
              " 'everything changed\\t모든 것이 변했어',\n",
              " 'everything stopped\\t모든 것이 멈췄어',\n",
              " 'excuse me a minute\\t잠깐 실례합니다',\n",
              " 'he kept me waiting\\t그는 나를 기다리게 했다',\n",
              " 'i baked tom a cake\\t나는 톰에게 케이크를 구워줬다',\n",
              " 'i didnt know that\\t그건 몰랐어요',\n",
              " 'i dont understand\\t이해가 안돼',\n",
              " 'i feel very guilty\\t나는 큰 죄책감을 느끼고 있어',\n",
              " 'i have a black dog\\t나는 검은색 강아지를 키우고 있어',\n",
              " 'i have to go alone\\t난 혼자서 가야해',\n",
              " 'i knew i would win\\t내가 이길 거라는 걸 알고 있었어',\n",
              " 'i love red parrots\\t난 빨간색 앵무새가 좋아',\n",
              " 'i love this school\\t난 이 학교를 좋아해',\n",
              " 'i need to warn tom\\t나는 톰에게 경고해야 해',\n",
              " 'i often read books\\t저는 자주 책을 읽습니다',\n",
              " 'i really like snow\\t나는 눈이 정말 좋아요',\n",
              " 'i really like snow\\t난 눈이 정말 좋아',\n",
              " 'i tried not to cry\\t난 울지 않으려고 노력했어',\n",
              " 'i tried not to cry\\t나는 울지 않으려고 했다',\n",
              " 'i want to be happy\\t나는 행복해지고 싶어',\n",
              " 'i wanted red shoes\\t빨간색 신발을 원했어',\n",
              " 'i was born in 2013\\t난 2013년에 태어났어',\n",
              " 'i wasnt even here\\t난 심지어 여기에 없었어',\n",
              " 'i wasnt even here\\t난 심지어 여기 없었어',\n",
              " 'ill be there soon\\t곧 갈게',\n",
              " 'im like my father\\t나는 우리 아빠같아',\n",
              " 'im like my father\\t나는 우리 아빠를 닮았어',\n",
              " 'im still a member\\t난 아직도 회원이야',\n",
              " 'im very depressed\\t난 아주 우울해',\n",
              " 'ive caught a cold\\t감기 걸렸어',\n",
              " 'is that real blood\\t그거 진짜 피야',\n",
              " 'it must be a virus\\t이건 틀림없이 바이러스야',\n",
              " 'it was toms fault\\t이건 톰 탓이야',\n",
              " 'lets move the bed\\t침대를 옮기자',\n",
              " 'life is a delusion\\t인생은 허상이야',\n",
              " 'life is never easy\\t사는게 쉽지가 않아',\n",
              " 'no one believed me\\t아무도 날 믿지 않았어',\n",
              " 'return immediately\\t즉시 돌아와',\n",
              " 'she has small feet\\t그녀는 발이 작다',\n",
              " 'some water please\\t물 좀 주세요 제발',\n",
              " 'something happened\\t무언가 일어났어',\n",
              " 'something happened\\t무언가 생겼어',\n",
              " 'stop looking at me\\t나좀 그만 봐',\n",
              " 'thats unavoidable\\t그건 피할 수 없어',\n",
              " 'the light went out\\t전등이 꺼졌다',\n",
              " 'the night was cold\\t그날 밤은 추웠어',\n",
              " 'the room was quiet\\t방은 조용했어',\n",
              " 'the spider is dead\\t거미가 죽었어',\n",
              " 'they have no proof\\t그들에게는 증거가 없었다',\n",
              " 'they have no proof\\t그들한텐 증거가 없어',\n",
              " 'tie your shoelaces\\t신발끈을 묶으세요',\n",
              " 'tom bought a horse\\t톰은 말을 샀어',\n",
              " 'tom could be lying\\t톰이 거짓말을 하고 있을 수 있다',\n",
              " 'tom died on monday\\t톰은 월요일에 죽었어',\n",
              " 'tom got very happy\\t톰은 아주 행복해졌어',\n",
              " 'tom has aspergers\\t톰은 아스퍼거야',\n",
              " 'tom hired a lawyer\\t톰이 변호사를 고용했어',\n",
              " 'tom hired a lawyer\\t톰은 변호사를 고용했다',\n",
              " 'tom is a rough man\\t톰은 거친 남자야',\n",
              " 'tom is a timid kid\\t톰은 소심한 애야',\n",
              " 'tom is openminded\\t톰은 개방적이야',\n",
              " 'tom is quite a guy\\t톰은 꽤 남자다워',\n",
              " 'tom made me a cake\\t톰이 날 위해 케이크를 만들었어',\n",
              " 'tom never helps me\\t톰은 날 절대 안 도와줘',\n",
              " 'tom said hes weak\\t톰은 자신이 약하다고 말했다',\n",
              " 'tom was astonished\\t톰은 깜짝 놀랐다',\n",
              " 'tom wont be bored\\t톰은 지루해하지 않을 거야',\n",
              " 'we were retreating\\t우리는 후퇴하고 있었다',\n",
              " 'were still eating\\t우린 아직도 먹는 중이야',\n",
              " 'were still eating\\t우린 아직도 먹고 있어',\n",
              " 'weve been worried\\t계속 걱정했어',\n",
              " 'when will you come\\t언제쯤 올거야',\n",
              " 'wheres tom hiding\\t톰은 어디에 숨어 있어',\n",
              " 'whose book is this\\t이것은 누구의 책입니까',\n",
              " 'wifi is available\\t와이파이 돼',\n",
              " 'youre very astute\\t넌 참 눈치가 빠르네',\n",
              " 'am i older than you\\t내가 너보다 나이가 많아',\n",
              " 'are you still alone\\t너 아직도 혼자야',\n",
              " 'can i have this cup\\t이 컵 가져도 돼요',\n",
              " 'chivalry isnt dead\\t기사도는 죽지 않았다',\n",
              " 'do you go to school\\t학교에 다녀',\n",
              " 'do you have a house\\t집 있어요',\n",
              " 'do you like english\\t영어 좋아해요',\n",
              " 'do you like english\\t영어 좋아해',\n",
              " 'do you like cooking\\t요리 좋아해요',\n",
              " 'do you like cooking\\t요리 좋아해',\n",
              " 'do you like singing\\t노래하는 거 좋아해요',\n",
              " 'do you like singing\\t노래하는 거 좋아해',\n",
              " 'dont you like cats\\t고양이를 좋아하지 않아',\n",
              " 'dreams do come true\\t꿈은 이루어질 거야',\n",
              " 'everybody loves her\\t모두 그녀를 사랑한다',\n",
              " 'everybody loves him\\t모두가 그를 사랑한다',\n",
              " 'everythings normal\\t모든 것이 정상이야',\n",
              " 'hes in his fifties\\t그 사람은 오십 대야',\n",
              " 'his dream came true\\t그 사람의 꿈은 실현되었어',\n",
              " 'how may i serve you\\t어떻게 도와드릴까요',\n",
              " 'i acted like a fool\\t나는 바보같이 굴었어',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l[:5] #\\t - 탭"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0UBQQi0DBiF",
        "outputId": "95790e4e-b40c-4d14-a304-a099c3ff367f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go\\t가', 'hi\\t안녕', 'run\\t뛰어', 'run\\t뛰어', 'who\\t누구']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습용 데이터 만들기"
      ],
      "metadata": {
        "id": "9uJ7SQ2xDNlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단어가 10개를 넘지 않는 문장들만 사용\n",
        "* 문장을 불러올 때 <EOS(End Of Speech)> 토큰을 추가해서 문장이 끝났음을 알림"
      ],
      "metadata": {
        "id": "8amudxBvDUcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "id": "Tp5Ac8oiDn24"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOW를 만드는 함수 정의"
      ],
      "metadata": {
        "id": "vFh4bwZ8DoOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_BOW(corpus): # 말뭉치 -> 문장 -> BOW를 만드는 함수\n",
        "    BOW = {\"<SOS>\": 0, \"<EOS>\": 1}\n",
        "    # BOW 안에 문장의 시작과 끝을 알리는\n",
        "    # SOS(Start Of Speech) 토큰과 EOS(End Of Speech) 토큰을 추가\n",
        "\n",
        "    # 문장 내 단어들을 사용하여 BOW를 생성\n",
        "    for line in corpus:\n",
        "        for word in line.split():\n",
        "            if word not in BOW.keys(): # 등록되지 않은 단어면\n",
        "                BOW[word] = len(BOW.keys())\n",
        "                # 사전에 추가해주는데, 해당 단어의 고유번호는 이전까지의 키의 갯수\n",
        "    return BOW"
      ],
      "metadata": {
        "id": "WrQ7qjwYD05b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습용 데이터셋 정의"
      ],
      "metadata": {
        "id": "zD_EagauE2fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Eng2Kor(Dataset):\n",
        "    def __init__(self, path='./corpus.txt') -> None:\n",
        "        super().__init__()\n",
        "        self.eng_corpus = [] # 영어문장이 들어가는 변수\n",
        "        self.kor_corpus = [] # 한글문장이 들어가는 변수\n",
        "\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "            for line in lines: # 문장\n",
        "                txt = \"\".join(v for v in line\n",
        "                              if not v in string.punctuation).lower()\n",
        "                # \\t 구분이 되어 있었음 (영어와 한글) -> 탭을 기준으로 분리\n",
        "                engtxt, kortxt = txt.split('\\t') # 0 : 영어 # 1 : 한글\n",
        "                # engtxt = txt.split('\\t')[0]\n",
        "                # kortxt = txt.split('\\t')[1]\n",
        "\n",
        "                # 길이가 10 이하인 문장 = 단어의 갯수가 10개 이하인 문장만 학습\n",
        "                if len(engtxt.split()) <= 10 and len(kortxt.split()) <= 10:\n",
        "                    # 영어, 한글 번역문 모두 10개 단어 이하인 데이터만 사용\n",
        "                    self.eng_corpus.append(engtxt)\n",
        "                    self.kor_corpus.append(kortxt)\n",
        "        \n",
        "        # 영어와 한글 문장을 각각 BOW(단어 사전)으로 변환\n",
        "        self.engBOW = get_BOW(self.eng_corpus)\n",
        "        self.korBOW = get_BOW(self.kor_corpus)\n",
        "    \n",
        "    # 문장을 단어별로 분리하는 함수\n",
        "    def gen_seq(self, line): # line = 문장\n",
        "        seq = line.split() # 토큰화 한다음에\n",
        "        seq.append('<EOS>') # 마지막에 EOS(문장 끝) 토큰 추가\n",
        "        return seq\n",
        "\n",
        "    def __len__(self): # 데이터의 개수를 반환하는 함수\n",
        "        return len(self.eng_corpus)\n",
        "\n",
        "    # 데이터와 정답을 반환하는 함수\n",
        "    def __getitem__(self, i): # data, label을 지정\n",
        "        # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n",
        "        # 1) 영어 corpus 중 i번째 문장을 받아옴\n",
        "        # 2) gen_seq -> i번째 문장을 seq 형태로 변환 (토큰+EOS)\n",
        "        # 3) 단어 사전을 사용해서 고유번호 형태로 변환 (학습을 위해 숫자형태로 변환)\n",
        "        # self.eng_corpus[i] -> self.gen_seq(self.eng_corpus[i])\n",
        "        # -> [self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])]\n",
        "        data = np.array([\n",
        "            [self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])]\n",
        "        ])\n",
        "        label = np.array([\n",
        "            [self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])]\n",
        "        ])\n",
        "        return data, label # 영어 데이터 (입력) -> 한글 데이터 (정답)"
      ],
      "metadata": {
        "id": "jFiIQebMEwD_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로더"
      ],
      "metadata": {
        "id": "7hyu5o55qrQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loader(dataset): # 데이터셋의 문장을 한 문장씩 불러오기 위한 함수 정의\n",
        "    for i in range(len(dataset)):\n",
        "        data, label = dataset[i]\n",
        "\n",
        "        # 데이터와 정답을 반환\n",
        "        yield torch.tensor(data), torch.tensor(label)\n",
        "        # yield : 리턴과 유사, 값을 반복적으로 반환"
      ],
      "metadata": {
        "id": "8_zGEJvFqrBs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 정의"
      ],
      "metadata": {
        "id": "UPINig5DrTOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인코더 정의\n",
        "* 임베딩층, GRU층"
      ],
      "metadata": {
        "id": "za-92TOSrXSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size) -> None:\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # 임베딩층\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # GRU층\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        # nn.GRU : GRU 계산. input_size, hidden_size, num_layers)\n",
        "    \n",
        "    def forward(self, x, h): # x: 입력값 / h : 은닉상태\n",
        "        # 배치 차원과 시계열 차원 추가\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(x, h) # output : 문장의 특성, hidden 은닉 상태\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "003BAHh4rehb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디코더 정의\n",
        "* 임베딩 층\n",
        "* 전결합 층 (ReLU)\n",
        "* 전결합 층 (Softmax)\n",
        "* 내적\n",
        "* GRU층"
      ],
      "metadata": {
        "id": "wNA-b81Itgjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11) -> None:\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # 임베딩 층 정의\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # 어텐션 가중치를 계산하기 위한 MLP층\n",
        "        self. attention = nn.Linear(hidden_size * 2, max_length)\n",
        "        # 10개 + <EOS>(1) = 최대 길이 11개\n",
        "\n",
        "        # 특징 추출을 위한 MLP층\n",
        "        self.context = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "        # 오버피팅을 피하기 위한 드롭아웃층\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        # GRU층\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # 단어 분류를 위한 MLP층\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # 활성화 함수\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sofrmax = nn.LogSoftmax(dim=1)\n",
        "        # LogSoftmax(dim) : 소프트맥스 함수에 로그 값을 취한 것을 반환\n",
        "        # dim -> 계산의 대상이 될 차원값\n",
        "    \n",
        "    def forward(self, x, h, encoder_outputs): # x : 입력값, h : 은닉상태, e...: 인코더 결과값\n",
        "        # 입력 받은 x(현 시점의 디코더 입력)을 임베딩 층을 사용해 밀집 표현으로 변환\n",
        "        # 배치 차원, 시계열 차원, 단어들.\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        x = self.dropout(x)\n",
        "        # 어텐션 가중치 계산\n",
        "        attn_weights = self.softmax(\n",
        "            self.attention(torch.cat((x[0], h[0]), -1))\n",
        "        )\n",
        "\n",
        "        # 어텐션 가중치와 인코더의 출력을 내적(크기가 다른 두 배열을 방향이 일치하는 만큼 곱함)\n",
        "        attn_applied = torch.bmm(\n",
        "            attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)\n",
        "        ) # bmm(A, B) : A 크기가 (B, N, M)이고, B 크기가 (B, M, K)\n",
        "        # => (B, N, K) 크기의 출력을 반환 -> 유사도\n",
        "\n",
        "        # 인코더 각 시점의 중요도와 밀집 표현을 합쳐서 MLP층으로 특징 추출\n",
        "        output = torch.cat((x[0], attn_applied[0]), 1)\n",
        "        output = self.context(output).unsqueeze(0)\n",
        "        output = self.relu(output)\n",
        "        # 인코더의 중요도(attn_applied)와 현시점에서의 디코더의 밀집표현(x)을 합쳐서\n",
        "        # MLP층(context)으로 입력\n",
        "        # -> MP층은 인코더 각 시점의 중요도와 현시점 디코더의 밀집표현을 동시에 처리\n",
        "        # -> 인코더의 중요도가 디코더의 반영\n",
        "\n",
        "        # GRU층으로 입력\n",
        "        output, hidden = self.gru(output, h)\n",
        "\n",
        "        # 예측된 단어를 출력\n",
        "        output = self.out(output[0])\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "CDqJvnMJtX11"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 정의"
      ],
      "metadata": {
        "id": "IOuGn4jC44GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습에 필요한 요소 정의"
      ],
      "metadata": {
        "id": "CyiuJmmk47HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "# 학습에 사용할 데이터셋\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n",
        "# 인코더와 디코더 학습을 위한 최적화 함수 정의\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = Adam(decoder.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "42VTmT0Ps72D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qZiVal6U580O",
        "outputId": "294c4176-1816-4f0b-b78f-132b6f4215de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 루프 정의"
      ],
      "metadata": {
        "id": "lR0tenX96W95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    iterator = tqdm(loader(dataset), total=len(dataset))\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in iterator:\n",
        "        data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "        # 인코더의 초기 은닉 상태\n",
        "        encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "        # 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "        # 최대 단어 10개 + 종료(EOS) -> 11개\n",
        "        encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # 인코더 동작\n",
        "        for ei in range(len(data)): # data : 토큰화, 고유번호 -> 단어들의 리스트\n",
        "            # ei => data의 인덱스들\n",
        "            # 한 단어씩 인코더에 넣어줌\n",
        "            encoder_output, encoder_hidden = encoder(data[ei], encoder_hidden)\n",
        "\n",
        "            # 인코더의 은닉상태를 저장\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        \n",
        "        decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "        # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 지정\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # 디코더 동작\n",
        "        # 티처 포싱 (Teacher Forcing: 교사 강요)\n",
        "        # Seq2Seq 구조에서 현시점의 입력을 (모델의 예측값을 사용하는 대신에) 정답을 이용하는 방법\n",
        "        # 엉뚱한 답을 피하고, 시간 단축을 위해 강제적으로 정답을 넣어주는 기술 (50% 확률로 적용)\n",
        "        use_teacher_forcing = True if random. random() < 0.5 else False\n",
        "        \n",
        "        if use_teacher_forcing:\n",
        "            for di in range(len(label)):\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs\n",
        "                )\n",
        "\n",
        "\n",
        "                target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decorder_output, target)\n",
        "\n",
        "                # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n",
        "                decorder_input = target # 바꿔치기\n",
        "        else:\n",
        "            for di in range(len(label)):\n",
        "                decorder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "                \n",
        "                target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decorder_output, target)\n",
        "\n",
        "                # 가장 높은 확률을 갖는 단어의 인덱스 topi\n",
        "                topv, topi = decoder_output.topk(1) # top k -> (1)개를 불러옴\n",
        "\n",
        "                # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n",
        "                decoder_input = topi.squeeze().detach() # 텐서 -> 값\n",
        "\n",
        "                \n",
        "                if decoder_input.item() == 1: #<EOS> 토큰을 만나면 중지\n",
        "                    break\n",
        "        \n",
        "        # 전체 손실 계산\n",
        "        total_loss += loss.item() / len(dataset)\n",
        "        iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "torch.save(encoder.state_dict(), \"attn_enc.pt\")\n",
        "torch.save(decoder.state_dict(), \"attn_dec.pt\")"
      ],
      "metadata": {
        "id": "oM5eo7gf6UrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522,
          "referenced_widgets": [
            "ddded2a5f13949b1a362857fa36e3303",
            "11e4eb93183c4dadbd84ac0824f52ac8",
            "2e4521fb01fd45759aea0cf063e1891f",
            "348615891e294b298adbe4f9916da5d6",
            "e145313f3c714d24baa877d47dfefad6",
            "2b348d98ad194f39aaaa2d96a2f549e3",
            "fa58533093b54d47afcc2e9da782d49d",
            "5f27fb097846449d82a45989aa85166a",
            "1335e49cd4274a068edf645162a83818",
            "d99c601e7e40421ab37b95dda27ba7e5",
            "1c0acb7a783d4fb991bfb9049fbd13e1"
          ]
        },
        "outputId": "878f119f-8c4c-49a4-967c-bf611a24ae54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3592 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddded2a5f13949b1a362857fa36e3303"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-2d4f54e08675>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(data, dtype=torch.long).to(device)\n",
            "<ipython-input-17-2d4f54e08675>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(label, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2d4f54e08675>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# ei => data의 인덱스들\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# 한 단어씩 인코더에 넣어줌\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# 인코더의 은닉상태를 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-7fd801cd245c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 배치 차원과 시계열 차원 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output : 문장의 특성, hidden 은닉 상태\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    219\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    220\u001b[0m                     self.input_size, input.size(-1)))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 64, got 128"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/BigData23th/Data/raw/main/attn_enc.pt\n",
        "!wget https://github.com/BigData23th/Data/raw/main/attn_dec.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAsM-EwPDLgl",
        "outputId": "9b48cff5-c8cb-48df-fb14-889e34703cb8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 03:35:30--  https://github.com/BigData23th/Data/raw/main/attn_enc.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/attn_enc.pt [following]\n",
            "--2023-04-07 03:35:30--  https://raw.githubusercontent.com/BigData23th/Data/main/attn_enc.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 727147 (710K) [application/octet-stream]\n",
            "Saving to: ‘attn_enc.pt’\n",
            "\n",
            "attn_enc.pt         100%[===================>] 710.10K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-04-07 03:35:31 (126 MB/s) - ‘attn_enc.pt’ saved [727147/727147]\n",
            "\n",
            "--2023-04-07 03:35:31--  https://github.com/BigData23th/Data/raw/main/attn_dec.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/attn_dec.pt [following]\n",
            "--2023-04-07 03:35:31--  https://raw.githubusercontent.com/BigData23th/Data/main/attn_dec.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2857305 (2.7M) [application/octet-stream]\n",
            "Saving to: ‘attn_dec.pt’\n",
            "\n",
            "attn_dec.pt         100%[===================>]   2.72M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-04-07 03:35:32 (224 MB/s) - ‘attn_dec.pt’ saved [2857305/2857305]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 평가"
      ],
      "metadata": {
        "id": "Xj6sqB6TDZFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pt\", map_location=device))\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pt\", map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-See_gDDSvg",
        "outputId": "88afa1a7-7305-4fbd-8c3c-df9d811ff956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불러올 영어 문장을 랜덤하게 지정\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "input_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "axp4313pDnt7",
        "outputId": "7643860c-7327-4f96-f89a-c15fe95f14c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i just want to rest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\""
      ],
      "metadata": {
        "id": "2KR-fniJD-9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device) # 영어문장\n",
        "label = torch.tensor(label, dtype=torch.long).to(device) # 한국어문장"
      ],
      "metadata": {
        "id": "wpQit4YVEGvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxAVPvZcEbZl",
        "outputId": "e0efd8f0-7ee6-4bf7-ebce-d3f4c855e9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([139, 135,   1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr73uVzPEXEp",
        "outputId": "5d87c184-68c9-4adb-a0d3-33ee76865868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([179, 175, 254,   1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인코더 동작"
      ],
      "metadata": {
        "id": "mTYzESGiEtfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더의 초기 은닉 상태 정의\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "# 인코더 출력을 담기 위한 변수\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)"
      ],
      "metadata": {
        "id": "_WwZLartEu1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ei in range(len(data)):\n",
        "    # 한 단어씩 인코더에 넣어줌\n",
        "    encoder_output, encoder_hidden = encoder(\n",
        "        data[ei], encoder_hidden\n",
        "    )\n",
        "    # 인코더의 출력을 저장\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]"
      ],
      "metadata": {
        "id": "13okMEhfE6K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs"
      ],
      "metadata": {
        "id": "Bumb4Mr1FP8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디코더 동작"
      ],
      "metadata": {
        "id": "4JsCvUSrFMaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 초기 입력\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "# 0 -> 문장이 시작되었다는 SOS 토큰\n",
        "\n",
        "# 인코더의 마지막 은닉 상태 -> 디코더의 초기 은닉 상태\n",
        "decoder_hidden = encoder_hidden"
      ],
      "metadata": {
        "id": "YtbFVngTFN5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for di in range(11):\n",
        "    # 디코더 모델을 통해서 단어별 나올 확률\n",
        "    decoder_output = decoder(\n",
        "        decorder_input, decoder_hidden, encoder_outputs\n",
        "    )\n",
        "    # 가장 높은 확률을 갖는 단어의 요소 계산\n",
        "    topv, topi = decoder_output.topk(1)\n",
        "    # 가장 높은 확률의 단어\n",
        "    decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    # EOS 토큰을 만나면 중지\n",
        "    if decoder_input.item() == 1:\n",
        "        break\n",
        "    \n",
        "    # 예측 문자열에 가장 높은 확률의 단어를 추가\n",
        "    pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n",
        "\n",
        "print(input_sentence)\n",
        "print(pred_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRyfeY8OFjuB",
        "outputId": "6f1093b4-034e-4304-8dab-650a503ef636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i just want to rest\n",
            "싶어 싶어 싶어 싶어 이걸 어제 이걸 싶어 쉬고 싶어 이걸 함께 함께 이걸 싶어 싶어 싶어 싶어 싶어 싶어 싶어 이걸 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 통합"
      ],
      "metadata": {
        "id": "uQdzZcLYJi11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NyU4tGQKhrH",
        "outputId": "57ff182a-7a01-407f-968e-a1105dd76cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "# 학습에 사용할 데이터셋\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n",
        "\n",
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pt\", map_location=device))\n",
        "# 디코더 가중치 불러오기\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pt\", map_location=device))\n",
        "\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\"\n",
        "\n",
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "for ei in range(len(data)):\n",
        "   encoder_output, encoder_hidden = encoder(\n",
        "       data[ei], encoder_hidden)\n",
        "     \n",
        "   encoder_outputs[ei] = encoder_output[0, 0]  \n",
        "\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "decoder_hidden = encoder_hidden \n",
        "\n",
        "for di in range(11):\n",
        "   decoder_output = decoder(\n",
        "                       decoder_input, decoder_hidden, encoder_outputs)\n",
        "   topv, topi = decoder_output.topk(1)\n",
        "   decoder_input = topi.squeeze().detach()\n",
        "\n",
        "   if decoder_input.item() == 1:  \n",
        "       break\n",
        "\n",
        "   pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"  \n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from time import sleep\n",
        "\n",
        "file_name = '/content/sample.mp3'\n",
        "\n",
        "text = input_sentence\n",
        "tts_en = gTTS(text=text)\n",
        "tts_en.save(file_name)\n",
        "\n",
        "print(input_sentence)  # 영어 문장\n",
        "wn = Audio(file_name, autoplay=True)\n",
        "display(wn)\n",
        "\n",
        "sleep(4)\n",
        "\n",
        "text = pred_sentence\n",
        "tts_ko = gTTS(text=text, lang='ko')\n",
        "tts_ko.save(file_name)\n",
        "print(pred_sentence)  # 한글 문장\n",
        "\n",
        "wn = Audio(file_name, autoplay=True)\n",
        "display(wn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "OmQ0IotPJkF_",
        "outputId": "25b3f18d-6d23-4327-beaf-c2166f408ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "any questions\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아무 질문이라도 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}