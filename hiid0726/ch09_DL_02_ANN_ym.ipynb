{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiid0726/DeepLearning/blob/main/hiid0726/ch09_DL_02_ANN_ym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 신경망 모델 구현하기"
      ],
      "metadata": {
        "id": "CpPjB6ksx-ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인공 신경망 (ANN)\n",
        "artificial neural network, ANN"
      ],
      "metadata": {
        "id": "fxL1qxvCyBA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 인간의 신경계의 작동 방식에서 영감을 받음\n",
        "    * 자극 → (감각 기관) → (신경 세포 1) → (신경 세포 2) → ... \n",
        "* 입력층 input layer : 자극을 입력받는 감각기관에 해당\n",
        "* 은닉층 hidden layer (혹은 중간층) : 입력층을 거친 자극이 지나가는 곳\n",
        "* 출력층 output layer : 마지막으로 전달되는 뉴런\n",
        "* 각 층에 존재하는 한 단위의 인공 뉴런을 노드 node 라고 함\n",
        "![인공신경망](https://github.com/BigData23th/Data/raw/main/dl_01_03.jpg)"
      ],
      "metadata": {
        "id": "-OW7qZBHySQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 인공 신경망의 각 노드는 입력된 자극에 특정한 수학 연산을 실행\n",
        "* 각 층에 존재하는 매개변수인 가중치 weight 에 행렬곱시키고 편향 bias 를 더해줌\n",
        "    * **가중치** : 입력 신호가 출력에 주는 영향을 계산하는 매개변수\n",
        "    * **편향** : 각 노드가 얼마나 데이터에 민감한지 알려주는 매개변수\n",
        "* 이 행렬곱의 결과는 활성화 함수 activation function 을 거쳐 인공뉴런의 결괏값을 산출하게 됨\n",
        "    * **활성화 함수** : 입력에 적절한 처리를 해서 출력 신호로 변환하는 함수\n",
        "    * 입력 신호의 합이 활성화를 일으키는지 아닌지(얼마나 출력할지)를 정하는 역할\n",
        "\n",
        "![가중치, 편향, 활성화 함수](https://github.com/BigData23th/Data/raw/main/dl_01_04.jpg)"
      ],
      "metadata": {
        "id": "oWZKNcvQzgQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 노드를 통해 나온 결괏값은 이어지는 은닉층의 인공뉴런으로 전달되고, 가중치 곱 & 활성화 함수를 거치게 됨\n",
        "\n",
        "> 이러한 뉴런 간의 자극 처리와 전달 과정을 몇 겹에 걸쳐 반복한 후 마지막 출력층에서 결괏값을 만들어내는 것\n",
        "\n",
        "* 인공 신경망의 출력층이 낸 결괏값과 정답을 비교해 오차를 계산해야 함\n",
        "* 이 오차를 기반으로 신경망 전체를 학습시키려면 출력층이 가중치부터 입력층의 가중치까지 모두 경사하강법을 활용해 변경해줘야 함\n",
        "* 이렇게 겹겹이 쌓인 가중치를 뒤에서부터 차례대로 조정하고 최적화하는 알고리즘 = 역전파 Backpropagation 알고리즘 (오차역전파)\n",
        "---\n",
        "* https://youtu.be/p9M0A1VBUpM\n",
        "* https://youtu.be/1Q_etC_GHHk\n",
        "* https://youtu.be/573EZkzfnZ0"
      ],
      "metadata": {
        "id": "GBJfymwg0sAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 간단한 분류 모델 구현"
      ],
      "metadata": {
        "id": "mSeMMWg66FRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망의 학습과 평가에 사용할 데이터셋 만들기\n",
        "from sklearn.datasets import make_blobs\n",
        "# make_blobs() : 데이터를 2차원 벡터 형태로 만든 데이터셋을 생성"
      ],
      "metadata": {
        "id": "xGpZZDqYzfus"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uVoN6UQuxO0D"
      },
      "outputs": [],
      "source": [
        "n_dim = 2 # 차원\n",
        "# 좌표값 / 분류.라벨.정답값\n",
        "# Train\n",
        "x_train, y_train = make_blobs(\n",
        "    random_state=100,\n",
        "    n_samples=80, # 추출할(생성할) 샘플(데이터) 갯수\n",
        "    n_features=n_dim, # 차원의 수 (특성 갯수)\n",
        "    centers=[[1, 1], [-1, -1], [1, -1], [-1, 1]], # 중심점들 (예시 : 4개)\n",
        "    shuffle=True,\n",
        "    cluster_std=0.3 # 중심점으로부터 얼마나 퍼져있을 건지 (표준편차)\n",
        ")\n",
        "# → 인덱스를 생성해주는 함수. (0, 1, 2, 3)\n",
        "# → 각 데이터 한 점 한 점이 몇 번째 클러스터에 속해 있는지 알려주는 인덱스\n",
        "# x (좌표), y(인덱스->몇번째 클러스터에 속해있는지)\n",
        "# Test\n",
        "x_test, y_test = make_blobs(\n",
        "    random_state=100,\n",
        "    n_samples=20, # 추출할(생성할) 샘플(데이터) 갯수\n",
        "    n_features=n_dim, # 차원의 수 (특성 갯수)\n",
        "    centers=[[1, 1], [-1, -1], [1, -1], [-1, 1]], # 중심점들 (예시 : 4개)\n",
        "    shuffle=True,\n",
        "    cluster_std=0.3 # 중심점으로부터 얼마나 퍼져있을 건지 (표준편차)\n",
        ")\n",
        "# 훈련 데이터 (학습 데이터) 80개 / 시험 데이터 20개"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZKsJ1MS736R",
        "outputId": "51af049e-846b-4eb8-ecb3-a4d55e4a92cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.90212858,  1.0167028 ],\n",
              "       [ 0.94449577, -1.74614546],\n",
              "       [-0.31040382,  0.95043713],\n",
              "       [-0.67189401,  0.93114467],\n",
              "       [-1.2586682 , -0.62515908],\n",
              "       [-0.99780563, -1.18388162],\n",
              "       [-1.42451288,  0.80777202],\n",
              "       [ 0.94315125,  1.07650043],\n",
              "       [ 1.34591074,  0.92426919],\n",
              "       [-0.86011019,  1.08099617],\n",
              "       [ 0.82635225, -1.35983536],\n",
              "       [-0.71529857,  0.99418072],\n",
              "       [-1.36517624,  0.95282045],\n",
              "       [-1.29499303, -0.89274767],\n",
              "       [ 0.48860464, -1.3408783 ],\n",
              "       [-1.55235649, -0.89017203],\n",
              "       [ 1.20181624,  0.96867666],\n",
              "       [-0.81608834, -0.77913844],\n",
              "       [ 1.09521039, -1.22572425],\n",
              "       [-0.61112122,  1.28568269],\n",
              "       [-1.02388337, -1.26691944],\n",
              "       [ 1.20703644, -0.79393298],\n",
              "       [-0.7758833 ,  1.12890293],\n",
              "       [ 1.03972834, -0.99333582],\n",
              "       [-0.94212484,  0.89546232],\n",
              "       [-0.76611211,  0.86856373],\n",
              "       [-1.09953314, -1.20676539],\n",
              "       [ 0.61108246, -0.97145817],\n",
              "       [ 0.86855931,  0.66450453],\n",
              "       [ 0.9253334 , -1.13505293],\n",
              "       [ 1.2193001 ,  1.40846684],\n",
              "       [ 0.8903614 , -1.38130691],\n",
              "       [ 1.29439624,  1.15426565],\n",
              "       [ 0.87288547, -1.35579507],\n",
              "       [-1.09594931,  0.65567752],\n",
              "       [-1.18498881,  1.22895509],\n",
              "       [-1.45227555,  1.03236524],\n",
              "       [-1.4190998 ,  0.6708484 ],\n",
              "       [-0.61007558, -1.51992869],\n",
              "       [-1.07161386,  0.57127993],\n",
              "       [-0.69192357, -1.42965718],\n",
              "       [ 1.0326616 , -0.99151491],\n",
              "       [ 0.8625919 ,  1.13054905],\n",
              "       [ 0.77309431,  1.2449362 ],\n",
              "       [-1.48407355, -0.55878584],\n",
              "       [-1.44931611,  0.64183421],\n",
              "       [-0.4889128 ,  0.78335477],\n",
              "       [-1.49065882, -1.31326296],\n",
              "       [-0.825828  , -1.33135693],\n",
              "       [-0.38961773, -1.16521432],\n",
              "       [-0.73162069,  1.22790794],\n",
              "       [ 1.23364672, -0.87153014],\n",
              "       [-0.96734096, -0.84765712],\n",
              "       [ 1.35688668,  0.49281495],\n",
              "       [ 1.56297203, -1.11307101],\n",
              "       [-1.26453952, -0.99440832],\n",
              "       [ 0.10800536, -0.99000482],\n",
              "       [ 0.47507036,  1.10280412],\n",
              "       [ 0.84061589,  1.30891981],\n",
              "       [ 1.47585128, -0.7919828 ],\n",
              "       [ 1.05535561,  1.28112466],\n",
              "       [ 0.52999374, -0.72850776],\n",
              "       [-0.37756205,  0.8970107 ],\n",
              "       [-1.28201385, -1.24837971],\n",
              "       [ 0.82492148,  1.24505412],\n",
              "       [ 0.97719296, -0.99881272],\n",
              "       [ 0.92443626,  0.74726928],\n",
              "       [ 0.41257563, -1.04044039],\n",
              "       [ 1.0663539 ,  0.678987  ],\n",
              "       [-1.16333175, -1.20045152],\n",
              "       [ 0.59308029,  0.63026965],\n",
              "       [ 1.06671988,  0.5670349 ],\n",
              "       [ 1.22513343,  0.86321592],\n",
              "       [-1.46218481,  1.61401419],\n",
              "       [-0.774864  , -1.3920977 ],\n",
              "       [ 1.4856945 ,  1.46248155],\n",
              "       [-0.92864661, -0.99593544],\n",
              "       [-1.35640528, -1.16492386],\n",
              "       [ 0.4882144 , -0.88925081],\n",
              "       [ 1.54958082, -0.99909477]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train # 0, 1, 2, 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOljwNMZ7_vi",
        "outputId": "43e5cf44-9633-4ce8-f479-1156116d2400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 3, 3, 1, 1, 3, 0, 0, 3, 2, 3, 3, 1, 2, 1, 0, 1, 2, 3, 1, 2,\n",
              "       3, 2, 3, 3, 1, 2, 0, 2, 0, 2, 0, 2, 3, 3, 3, 3, 1, 3, 1, 2, 0, 0,\n",
              "       1, 3, 3, 1, 1, 1, 3, 2, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 3, 1, 0, 2,\n",
              "       0, 2, 0, 1, 0, 0, 0, 3, 1, 0, 1, 1, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiBGs5Hy8GCI",
        "outputId": "c08332c8-cec7-46aa-85b8-db7be6a29bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.40691971,  0.63026965],\n",
              "       [-1.15938411, -0.69108019],\n",
              "       [ 1.0663539 ,  0.678987  ],\n",
              "       [-0.77486657,  0.86321592],\n",
              "       [ 0.47507036,  1.10280412],\n",
              "       [-1.13144069, -1.33549547],\n",
              "       [ 0.90212858, -0.9832972 ],\n",
              "       [ 1.05535561, -0.71887534],\n",
              "       [ 1.34591074,  0.92426919],\n",
              "       [-1.22690569,  1.2449362 ],\n",
              "       [ 1.2193001 , -0.59153316],\n",
              "       [-0.64311332,  0.49281495],\n",
              "       [ 1.4856945 , -0.53751845],\n",
              "       [ 1.29439624,  1.15426565],\n",
              "       [-0.93328012,  0.5670349 ],\n",
              "       [-1.17507852, -0.75494588],\n",
              "       [-0.79818376, -1.03132334],\n",
              "       [-1.1374081 , -0.86945095],\n",
              "       [ 0.94315125,  1.07650043],\n",
              "       [ 0.92443626, -1.25273072]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IkYI4oF8HzK",
        "outputId": "6c5db671-e419-495e-e70f-84ad35fb8bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 0, 3, 0, 1, 2, 2, 0, 3, 2, 3, 2, 0, 3, 1, 1, 1, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 이번에는 이진분류를 할 모델이기 때문에 레이블 합치기\n",
        "def label_map(y_, from_, to_):\n",
        "    y = np.copy(y_) # 얕은 복사 상태라서 y_의 원본에 영향을 미치지 않기 위해 copy로 깊은 복사\n",
        "    # y 복사본\n",
        "    for f in from_: # from_ : 리스트 : 0, 1 -> for문으로 반복해주겠다\n",
        "        # y : numpy 배열 -> 배열[  ] -> 인덱싱 -> 조건? -> 불리언 배열 인덱싱\n",
        "        # y_ == f : y_ (원본) 중에 f 값과 일치하는 경우 True\n",
        "        # 0 : y_ == 0 만 필터링 -> to_ -> y => 0\n",
        "        # 1 : y_ == 1 만 필터링 -> to_ -> y => 0\n",
        "        # 2 : y_ == 2 만 필터링 -> to_ -> y => 1\n",
        "        # 3 : y_ == 3 만 필터링 -> to_ -> y => 1\n",
        "        y[y_ == f] = to_\n",
        "    return y\n",
        "\n",
        "y_train = label_map(y_train, [0, 1], 0)\n",
        "y_train = label_map(y_train, [2, 3], 1)\n",
        "y_test = label_map(y_test, [0, 1], 0)\n",
        "y_test = label_map(y_test, [2, 3], 1)"
      ],
      "metadata": {
        "id": "B-Gs81yf8UOG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju4eT4JU9dKH",
        "outputId": "bf7d4841-8451-4fd2-a7d3-d822e1b862d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyuq8LPw9hoB",
        "outputId": "89fcc85e-fc61-4945-f626-306137e6ed88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 시각화\n",
        "def vis_data(x,y = None, c = 'r'):\n",
        "    if y is None:\n",
        "        y = [None] * len(x)\n",
        "    for x_, y_ in zip(x,y): # zip -> 같은 크기의 연속된 리스트를 같이 반복시켜줄 수 있는 기능\n",
        "        # 같은 번의 x, y 배열의 원소들 x_, y_\n",
        "        if y_ is None:\n",
        "            plt.plot(x_[0], x_[1], '*',markerfacecolor='none', markeredgecolor=c)\n",
        "        else: # x_[0] x좌표(가로), x_[1] y좌표(세로)\n",
        "            # c+'o' if y_ == 0 else c+'+'\n",
        "            # y_ == 0 이라면 c에다가 이어서 점을 의미하는 'o' 붙여달라\n",
        "            # 아니면 (y_ == 1) c... + 모양을 의미하는 '+' 붙여라\n",
        "            plt.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')\n",
        "\n",
        "plt.figure()\n",
        "# vis_data(x_train, y_train, c='r')\n",
        "vis_data(x_train, y_train, c='b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "TuIfRC3i9rBr",
        "outputId": "c266b92e-636b-49b5-9649-413f2ba00846"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-c263509ec536>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# vis_data(x_train, y_train, c='r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mvis_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-c263509ec536>\u001b[0m in \u001b[0;36mvis_data\u001b[0;34m(x, y, c)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# y_ == 0 이라면 c에다가 이어서 점을 의미하는 'o' 붙여달라\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# 아니면 (y_ == 1) c... + 모양을 의미하는 '+' 붙여라\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'o'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 → 텐서\n",
        "import torch\n",
        "\n",
        "# Numpy 배열 -> torch Tensor\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov-DlGGV_BC8",
        "outputId": "7aed35b4-eba7-45bc-e7c9-dae53bfe3589"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([80, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "x_test = torch.FloatTensor(x_test)"
      ],
      "metadata": {
        "id": "b_qgfIpR9_NT"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 모델을 구현\n",
        "# 파이토치에서는 신경망을 클래스 구현\n",
        "# 파이토치 -> 모듈. 이미 기본적인 설계도를 구현\n",
        "# torch.nn.Module -> 상속\n",
        "# class 이름:\n",
        "    # 클래스에 들어갈 기능(self, ...):\n",
        "    # ...\n",
        "class Glory:\n",
        "  def __init__(self):# 자동 호출\n",
        "    self.name = '연진'\n",
        "\n",
        "  def say(self):\n",
        "    print(f\"{self.name}아 나 지금 신나\")\n",
        "\n",
        "a= Glory();\n",
        "a.say()\n",
        "\n",
        "# 클래스이름(...?) -> 생성자 -> 특정한 변수에 클래스를 통해서 생성된 객체를 할당\n",
        "# 클래스가 가진 기능(메소드), 특성 또는 변수 (프로퍼티)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SlazXpb_okT",
        "outputId": "73d15d1c-fd89-4605-b2f3-99961ab7c524"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "연진아 나 지금 신나\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GloryPt2:\n",
        "  def __init__(self, name):# 자동 호출\n",
        "    self.name = name\n",
        "\n",
        "  def say(self):\n",
        "    print(f\"{self.name}아 나 지금 신나\")\n",
        "\n",
        "a= GloryPt2('동은');\n",
        "a.say()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU5LgTboA-1D",
        "outputId": "3cb0e4a9-c966-44b2-dc30-ac6cbad9db9d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "동은아 나 지금 신나\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상속하고 싶은 클래스를 옆에 괄호에 넣어줌\n",
        "class GloryPt3(GloryPt2):\n",
        "  pass\n",
        "\n",
        "a= GloryPt3('혜정');\n",
        "a.say()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYqSjfRtBo89",
        "outputId": "05ace2a0-5e41-43bc-f46f-dd844b551e24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "혜정아 나 지금 신나\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 신경망 모델 구현"
      ],
      "metadata": {
        "id": "ZD86Js0HVy-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.Module -> 상속 : 이미 구현된 클래스의 기능과 속성을 사용하는 것\n",
        "class NeuralNet(torch.nn.Module): # torch.nn.Module : 부모 클래스 / NeuralNet : 자식 클래스\n",
        "    # 생성자 __init__\n",
        "    # 신경망의 구조와 동작을 (부여, 결정) 정의하는 생성자를 모델 클래스(NeuralNet)에 정의(기록)\n",
        "    # __init__() : 파이썬에서 객체가 갖는 속성값을 초기화하는 역할\n",
        "    # 초기화 (initialization) : 할당된 자리에 값을 채워줌 / 어떤 값을 대입해 줌\n",
        "    # 정의 (definition) : (변수등의) 자리를 만들어 줌\n",
        "    # __init__ -> 객체가 생성되면 자동으로 호출(실행)됨\n",
        "    def __init__(self, input_size, hidden_size):    # 입력층과 은닉층의 사이즈를 초기화 시 결정\n",
        "        # 이미 정의된 nn.Module 활용해서 모델을 구성\n",
        "        # super.__init__() # 생성자를 super를 통해 직접 실행해서 부모 클래스의 생성자를 작동시킴\n",
        "        # super() 함수를 부르면 nn.Module(부모 클래스)의 속성들을 가지고 초기화\n",
        "        super(NeuralNet,self).__init__() #  --> 이렇게 해도 됨.\n",
        "        # ---\n",
        "        # 객체를 만들 때 input_size, hidden_size 입력\n",
        "        # input_size : 입력층 차원, hidden_size : 은닉층 차원\n",
        "        # self는 생성될 객체 그 자체를 의미\n",
        "        self.input_size = input_size # self -> input_size 속성이 생성 -> __init__ 전달받은 input_size가 부여\n",
        "        self.hidden_size = hidden_size   # self -> hidden_size 속성이 생성 -> __init__ 전달받은 hidden_size가 부여\n",
        "\n",
        "        # 인공 신경망 연산 정의 (층을 이동할 때 어떠한 계산이 일어날지)\n",
        "        # nn.Linear - 선형 결합, 행렬곱(가중치)과 편향(bias)를 포함하는 연산\n",
        "        # 입력층 -> 입력을 받아서 은닉층으로 넘겨줄 것\n",
        "        self.linear_1 = torch.nn.Linear(self.input_size, self.hidden_size) # 리니어는 입력과 출력을 이어주는 선! 인자는 입력갯수, 히든 갯수를 정의해주면 된다.\n",
        "        # 들어올 크기 -> 나갈 크기\n",
        "        # 활성화 함수\n",
        "        self.relu = torch.nn.ReLU() # Relu ->주로 쓰이는 활성화 함수  0보다 작으면 0으로 필터링, 0보다 크면 해당 값으로 필터링, 음수는 X\n",
        "        # linear_1 층을 통해서 -> 가중치 계산 -> relu 필터링 (0보다 작으면 0, 그보다 크면 그대로)\n",
        "        # 은닉층 -> 출력\n",
        "        self.linear_2 = torch.nn.Linear(self.hidden_size, 1) # 다음층의 입력은 이전층의 출력 값과 같다. /// 히든층에서 입력층으로 넘기는 인자 (단층은1, 다중일 경우 n)\n",
        "        # 이진분류 -> linear_1의 결과물을 받아서 -> 1개의 출력을 몰아줌 (0, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()# 이진분류에 사용되는 활성화 함수\n",
        "        # linear_1, relu, ... -> 함수처럼 쓰임\n",
        "    \n",
        "    # 가중치를 통해서 입력받은 값들을 변환하는 작업 : 순전파\n",
        "    def forward(self, input_tensor):\n",
        "\n",
        "    # 학습에 쓰일 텐서 (데이터)\n",
        "        # init() 함수에서 정의된 동작들을 차례로 실행\n",
        "        # linear1 : 입력 데이터 (input_tensor)에 [input_size, hidden_size] 크기의 가중치를 행렬 곱하고\n",
        "        # 편향을 더해서 [1, hidden_size] 의 텐서를 반환\n",
        "        linear1 = self.linear_1(input_tensor)\n",
        "        relu = self.relu(linear1) # [1, hidden_size]\n",
        "        # linear2 : [1, 1] 모양으로 변환\n",
        "        linear2 = self.linear_2(relu)\n",
        "        output = self.sigmoid(linear2)\n",
        "\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "2bvxJxtVV2Hl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReLU\n",
        "* ReLU : 입력값이 0보다 작으면 0을, 0보다 크면 입력값을 그대로 출력\n",
        "![ReLU](https://github.com/BigData23th/Data/raw/main/dl_01_05.jpg)"
      ],
      "metadata": {
        "id": "3DIixPXHZxEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시그모이드 sigmoid\n",
        "* 0과 1 사이의 값을 반환\n",
        "* 데이터를 0과 1 사이의 임의의 수로 제한해주어 결괏값이 0이나 1 중에 어디에 가까운지 알 수 있음\n",
        "![sigmoid](https://github.com/BigData23th/Data/raw/main/dl_01_06.jpg)"
      ],
      "metadata": {
        "id": "Lv6dvLkta5ZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링 진행"
      ],
      "metadata": {
        "id": "SAIvHSejcbso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape # 행 80, 열 2 -> 행은 데이터 하나 하나를 의미 -> [x좌표, y좌표]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mbu8ucXckcO",
        "outputId": "826d2109-43c1-4504-b43b-de670b14adc2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([80, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 객체를 생성\n",
        "model = NeuralNet(2,5) #input_size = 2, hidden_size = 5\n",
        "# 입력층 레이어 2, 은닉층 레이어 5"
      ],
      "metadata": {
        "id": "6FPWBJvkcah4"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 관련 변수와 알고리즘 정의\n",
        "# 학습률 설정\n",
        "learning_rate = 0.03 # 학습률 설정\n",
        "# 평가함수? 오차함수? 손실함수? -> 예측값(모델의 결과) vs 실제값(라벨링, 정답값)\n",
        "criterion = torch.nn.BCELoss() # 이진교차 엔트로피 (binary cross entropy) # 분류, 회귀..."
      ],
      "metadata": {
        "id": "infbYE6QdCO8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 에포크(이폭, epoch) : 전체 학습 데이터를 총 몇 번 모델에 입력할지 결정\n",
        "epochs = 2000\n",
        "# 너무 작게 설정하면 모델이 충분히 학습되지 않을 수 있음                (언더피팅, 과소적합)\n",
        "# 너무 크게 설정하면 모델 학습이 오래 걸리고, 새로운 데이터에 적응 못함 (오버피팅, 과적합)"
      ],
      "metadata": {
        "id": "xDPqV5DsiorA"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 사용할 최적화 알고리즘 결정\n",
        "# 확률적 경사하강법 stochastic gradient descent (SGD)\n",
        "# 새 가중치 = 가중치 - 학습률 x 가중치에 대한 기울기\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "# optimizer.step() 함수를 호출할 때마다 가중치를 학습률만큼 갱신\n",
        "# model.parameters() 함수로 모델 내부의 가중치를 추출 -> 가중치, 학습률"
      ],
      "metadata": {
        "id": "U4eVCirljSGb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아무 학습도 안 한 모델의 성능 시험\n",
        "model.eval() # evaluate (nn.Module) -> 시험모드로 설정\n",
        "# 임의의 가중치\n",
        "# 모델의 결과값과 레이블값(정답값)의 차원을 맞추기 위해 squeeze() -> 오차 구하기\n",
        "y_pred = model(x_test)\n",
        "y_pred, y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng86j0xWkM4n",
        "outputId": "c2807f56-3955-4066-b23a-10efd279a124"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5072],\n",
              "         [0.4678],\n",
              "         [0.5441],\n",
              "         [0.5263],\n",
              "         [0.5325],\n",
              "         [0.4938],\n",
              "         [0.5527],\n",
              "         [0.5460],\n",
              "         [0.5510],\n",
              "         [0.5642],\n",
              "         [0.5472],\n",
              "         [0.5018],\n",
              "         [0.5537],\n",
              "         [0.5527],\n",
              "         [0.5053],\n",
              "         [0.4669],\n",
              "         [0.4969],\n",
              "         [0.4713],\n",
              "         [0.5413],\n",
              "         [0.5622]], grad_fn=<SigmoidBackward0>),\n",
              " torch.Size([20, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-ZNMO1gQKtHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN9OmBqOk3Ae",
        "outputId": "fbd8dd28-acb1-44b8-9194-4098e938db32"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.4069,  0.6303],\n",
              "         [-1.1594, -0.6911],\n",
              "         [ 1.0664,  0.6790],\n",
              "         [-0.7749,  0.8632],\n",
              "         [ 0.4751,  1.1028],\n",
              "         [-1.1314, -1.3355],\n",
              "         [ 0.9021, -0.9833],\n",
              "         [ 1.0554, -0.7189],\n",
              "         [ 1.3459,  0.9243],\n",
              "         [-1.2269,  1.2449],\n",
              "         [ 1.2193, -0.5915],\n",
              "         [-0.6431,  0.4928],\n",
              "         [ 1.4857, -0.5375],\n",
              "         [ 1.2944,  1.1543],\n",
              "         [-0.9333,  0.5670],\n",
              "         [-1.1751, -0.7549],\n",
              "         [-0.7982, -1.0313],\n",
              "         [-1.1374, -0.8695],\n",
              "         [ 0.9432,  1.0765],\n",
              "         [ 0.9244, -1.2527]]),\n",
              " torch.Size([20, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_before = criterion(y_pred.squeeze(), y_test)"
      ],
      "metadata": {
        "id": "qdkCOBtZk7P7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "3872bcfb-cb38-4fa3-dff4-5b8025059377"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-f181719337fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3087\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([20, 2])) that is different to the input size (torch.Size([20])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'학습 전 loss는 {test_loss_before.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "anQpqL-KlGdX",
        "outputId": "a113a428-6278-4658-b223-8ab7da69576f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-68a33e7a83b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'학습 전 loss는 {test_loss_before.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loss_before' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습을 통한 성능 개선"
      ],
      "metadata": {
        "id": "dkHSyQbRlbH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs): # 2000번 돌리기\n",
        "    # 학습 모드로 전환\n",
        "    model.train()\n",
        "    \n",
        "    # 한 번 반복해주는 에포크마다, 새로운 경사값을 계산할 것이므로\n",
        "    # zero_grad() 함수를 호출해서 경사값(기울기)을 0으로 설정\n",
        "    optimizer.zero_grad()    # 그 전 기울기가 저장이 되어 있으므로 reset\n",
        "    # 학습 데이터를 입력해서 결과값을 개선\n",
        "    # x_train을 넣었을 때의 결과물\n",
        "    train_output = model(x_train) # output이 결과물이됨.\n",
        "    # nn.module -> 알아서 forward()를 호출해줌\n",
        "    \n",
        "    # 결과값의 차원과 레이블의 차원을 같게 만들고 오차를 계산\n",
        "    # loss_function\n",
        "    train_loss = criterion(train_output.squeeze(), y_train) # x_train -> 모델을 통해 나온 예측값 vs 실제 정답값 비교\n",
        "    # 100 에포크마다 오차를 출력해서 학습이 잘 되는지 확인 \n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"train loss at {epoch} : {train_loss.item()}\")\n",
        "    \n",
        "    # 오차함수(손실함수)를 가중치로 미분하여 오차가 최소가 되는 방향을 구하고,\n",
        "    # 그 방향으로 모델을 학습률만큼 이동시킴 (오차 역전파)\n",
        "    train_loss.backward() ## 역전파\n",
        "    # optimizer.step() 함수를 호출할 때마다 가중치를 학습률만큼 갱신"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "tm04VEIJlZj0",
        "outputId": "40b1778c-9429-4667-8beb-91d29dc9ba41"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-2b1324b0f7b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 결과값의 차원과 레이블의 차원을 같게 만들고 오차를 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# loss_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x_train -> 모델을 통해 나온 예측값 vs 실제 정답값 비교\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 100 에포크마다 오차를 출력해서 학습이 잘 되는지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3087\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([80, 2])) that is different to the input size (torch.Size([80])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 후 성능 측정"
      ],
      "metadata": {
        "id": "gkIa1_LMnrG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 모드로 바꾸기 + 테스트 데이터인 x_test & y_test를 통해 오차 구해보기\n",
        "# evaluate\n",
        "model.eval()\n",
        "test_loss = criterion(torch.squeeze(model(x_test)), y_test)\n",
        "print(f'학습 후 loss는 {test_loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0SB0EoTnqwb",
        "outputId": "85785515-416c-448d-a148-cd628452eea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 후 loss는 0.02007683739066124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(x_test), y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT7Z28cZoq7u",
        "outputId": "f958ca75-e6da-44c1-f88b-9fb933dd1833"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5072],\n",
              "         [0.4678],\n",
              "         [0.5441],\n",
              "         [0.5263],\n",
              "         [0.5325],\n",
              "         [0.4938],\n",
              "         [0.5527],\n",
              "         [0.5460],\n",
              "         [0.5510],\n",
              "         [0.5642],\n",
              "         [0.5472],\n",
              "         [0.5018],\n",
              "         [0.5537],\n",
              "         [0.5527],\n",
              "         [0.5053],\n",
              "         [0.4669],\n",
              "         [0.4969],\n",
              "         [0.4713],\n",
              "         [0.5413],\n",
              "         [0.5622]], grad_fn=<SigmoidBackward0>),\n",
              " tensor([[-1.4069,  0.6303],\n",
              "         [-1.1594, -0.6911],\n",
              "         [ 1.0664,  0.6790],\n",
              "         [-0.7749,  0.8632],\n",
              "         [ 0.4751,  1.1028],\n",
              "         [-1.1314, -1.3355],\n",
              "         [ 0.9021, -0.9833],\n",
              "         [ 1.0554, -0.7189],\n",
              "         [ 1.3459,  0.9243],\n",
              "         [-1.2269,  1.2449],\n",
              "         [ 1.2193, -0.5915],\n",
              "         [-0.6431,  0.4928],\n",
              "         [ 1.4857, -0.5375],\n",
              "         [ 1.2944,  1.1543],\n",
              "         [-0.9333,  0.5670],\n",
              "         [-1.1751, -0.7549],\n",
              "         [-0.7982, -1.0313],\n",
              "         [-1.1374, -0.8695],\n",
              "         [ 0.9432,  1.0765],\n",
              "         [ 0.9244, -1.2527]]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 저장 -> 딥러닝에서 모델을 저장 -> 레이어마다의 가중치를 저장\n",
        "# model.state_dict() : 모델 내의 가중치들을 딕셔너리 형태\n",
        "# {연산 이름: 가중치 텐서와 편향 텐서}와 같이 표현된 데이터\n",
        "torch.save(model.state_dict(), './model.pt') # .pth"
      ],
      "metadata": {
        "id": "ewleGn-EoPJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./model.pt')"
      ],
      "metadata": {
        "id": "4B_XdwpNo-rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용하려고 하는 모델 자체는 직접 구현 (Class 선언)\n",
        "new_model = NeuralNet(2, 5) # 아까 만든 model과는 다른 객체\n",
        "# .load_state_dict -> 이미 학습된 모델의 가중치를 적용\n",
        "new_model.load_state_dict(torch.load('./model.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uajGhTjapVa1",
        "outputId": "af9e1ed0-73da-4b93-a8ca-95091729023e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.eval()\n",
        "new_model(torch.FloatTensor([-1,1])).item() # 벡터 [-1,1] -> 레이블 1이 될 확률"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayHGPserptJ8",
        "outputId": "5d348e91-839b-4ec4-ebde-8ac3502db6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9590505361557007"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model(torch.FloatTensor([1,1])).item() # 벡터 [1,1] -> 레이블 1이 될 확률"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIo0VASA3QHn",
        "outputId": "e1372f9e-b872-4d13-9b69-0147391a6e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0018136772559955716"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}